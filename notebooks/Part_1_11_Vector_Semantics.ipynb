{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.di.uniroma1.it/sites/all/themes/sapienza_bootstrap/logo.png' width=\"200\"/>  \n",
    "\n",
    "# Part_1_11_Vector Semantics (Sparse)\n",
    "\n",
    "In Natural Language Processing (`NLP`), vector semantics provides a powerful framework for representing words and documents in a numerical form, enabling efficient computation and semantic analysis. Sparse vector representations, such as **Bag of Words (`BoW`)**, **TF-IDF**, and **Pointwise Mutual Information (`PPMI`)**, have been foundational in the evolution of `NLP`. These approaches rely on statistical co-occurrence patterns and word frequency to capture linguistic meaning, forming the basis for more sophisticated methods like dense embeddings and contextualized models.\n",
    "\n",
    "Sparse representations are particularly useful in understanding the core principles of vector semantics and building intuition about the role of word-document relationships in tasks like text classification, clustering, and retrieval systems.\n",
    "\n",
    "### **Objectives:**\n",
    "In this notebook, Parham provides an overview of sparse vector semantics, including the key methods used to represent text data and their significance in `NLP`. Through practical exercises, Parham will demonstrate the implementation of **Bag of Words (`BoW`)** for document representation, **TF-IDF** to highlight significant terms within documents, and **PPMI** to extract meaningful statistical relationships from co-occurrence matrices.\n",
    "\n",
    "### **References:**\n",
    "- [https://www.datacamp.com/tutorial/python-bag-of-words-model](https://www.datacamp.com/tutorial/python-bag-of-words-model)  \n",
    "- [https://spotintelligence.com/2022/12/20/bag-of-words-python](https://spotintelligence.com/2022/12/20/bag-of-words-python/)  \n",
    "- [https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus](https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus)   \n",
    "\n",
    "### **Tutors**:\n",
    "- Professor Stefano Farali\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: Stefano.faralli@uniroma1.it\n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/stefano-faralli-b1183920/) \n",
    "- Professor Iacopo Masi\n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: masi@di.uniroma1.it  \n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/iacopomasi/)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**: [GitHub](https://github.com/iacopomasi)  \n",
    "    \n",
    "\n",
    "### **Contributors:**\n",
    "- Parham Membari  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: p.membari96@gmail.com  \n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/p-mem/)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**: [GitHub](https://github.com/parham075)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Medium_logo_Monogram.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Medium**: [Medium](https://medium.com/@p.membari96)  \n",
    "\n",
    "**Table of Contents:**\n",
    "1. Import Libraries  \n",
    "2. Introduction to Vector Semantics  \n",
    "3. Bag of Words (`BoW`) Representation      \n",
    "4. Term Frequency-Inverse Document Frequency (`TF-IDF`)\n",
    "5. Pointwise Mutual Information (`PMI`)   \n",
    "6. Closing Thoughts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/p/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/p/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import tarfile\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "from nltk import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tag import pos_tag\n",
    "from loguru import logger\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from pprint import pprint\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Vector Semantics\n",
    "Vector semantics is a methodology in `NLP` that uses numerical representations to encode the meaning of words, phrases, or entire documents. These numerical representations are essential for enabling machines to process and analyze human language. By transforming textual data into vectors, computational models can perform mathematical operations to assess similarity, context, and relationships between words or documents.\n",
    "\n",
    "### Why Vector Semantics?\n",
    "- **Quantitative Representation**: Text data, being inherently qualitative, is challenging for computers to process directly. Vector semantics bridges this gap by converting text into a mathematical form.\n",
    "- **Efficient Computation**: Mathematical representations allow for quick calculations of similarity, clustering, and classification tasks.\n",
    "- **Foundation for Machine Learning Models**: Many machine learning models rely on vectorized representations of data as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Bag of Words (`BoW`) Representation \n",
    "\n",
    "**Bag of Words** (`BoW`) is a simple and widely-used representation of text data in Natural Language Processing. It represents text as a collection of words, ignoring grammar, word order, and context, while preserving the frequency of words.BoW boadly used in tasks such as text classification and sentiment analysis. This is important because machine learning algorithms canâ€™t process textual data. The process of converting the text to numbers is known as feature extraction or feature encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Understanding Bag of Words with example:\n",
    "Imagine two sentences:\n",
    "1. Document 1: \"Natural Language Processing is amazing.\"\n",
    "2. Document 2: \"Language models are important for NLP.\"\n",
    "\n",
    "\n",
    "The `BoW` model begins by creating a vocabulary, a unique list of all words across the corpus. Each document is then represented as a vector of word frequencies. Table below, represents the Bag of Words vectors:\n",
    "\n",
    "| **Vocabulary** | **Document 1** | **Document 2** |\n",
    "|-----------------|----------------|----------------|\n",
    "| Natural         | 1              | 0              |\n",
    "| Language        | 1              | 1              |\n",
    "| Processing      | 1              | 0              |\n",
    "| is              | 1              | 0              |\n",
    "| amazing         | 1              | 0              |\n",
    "| models          | 0              | 1              |\n",
    "| are             | 0              | 1              |\n",
    "| important       | 0              | 1              |\n",
    "| for             | 0              | 1              |\n",
    "| NLP             | 0              | 1              |\n",
    "\n",
    "Each position in the vector corresponds to a word in the vocabulary, and the value represents its frequency in the document.\n",
    "\n",
    "### How to implement `BoW`\n",
    "The steps involved to create `BoW` are:\n",
    "- Tokenization: Split the text into individual words or tokens.\n",
    "- Preprocessing:\n",
    "    - Convert text to lowercase.\n",
    "    - Remove special characters, punctuation, and numbers.\n",
    "    - Remove stopwords (e.g., \"the\", \"is\", \"and\").\n",
    "- Apply stemming or lemmatization to normalize words.\n",
    "- Vocabulary Creation: Build a unique list of words from the corpus.\n",
    "- Vectorization: Represent each document as a vector of word frequencies based on the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document 1</th>\n",
       "      <th>Document 2</th>\n",
       "      <th>Document 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>algorithm</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alli</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ancient</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>becam</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blur</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bridg</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>celebr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conflict</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>craft</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creativ</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cultur</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decod</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerg</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empath</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>everi</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>futur</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>give</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greatest</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heard</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>human</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instead</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interpret</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>languag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learn</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longer</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machin</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miscommun</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poetri</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precis</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shape</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>solv</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teach</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thrive</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tongu</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>translat</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ultim</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understand</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>understood</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voic</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>voiceless</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Document 1  Document 2  Document 3\n",
       "algorithm            0           1           0\n",
       "alli                 1           0           0\n",
       "ancient              1           0           0\n",
       "becam                1           0           0\n",
       "blur                 0           1           0\n",
       "bridg                1           0           0\n",
       "celebr               0           0           1\n",
       "conflict             0           1           0\n",
       "could                0           0           1\n",
       "craft                0           1           0\n",
       "creativ              0           1           0\n",
       "cultur               1           0           0\n",
       "decod                1           0           0\n",
       "emerg                1           0           0\n",
       "empath               0           1           0\n",
       "even                 1           0           0\n",
       "everi                0           0           1\n",
       "fear                 0           0           1\n",
       "forgotten            0           1           0\n",
       "futur                0           0           1\n",
       "give                 1           0           0\n",
       "greatest             1           0           0\n",
       "heard                0           0           1\n",
       "human                1           1           0\n",
       "instead              0           0           1\n",
       "interpret            0           0           1\n",
       "languag              1           0           1\n",
       "learn                0           1           0\n",
       "line                 0           1           0\n",
       "longer               0           0           1\n",
       "machin               0           1           0\n",
       "miscommun            0           0           1\n",
       "nlp                  1           0           1\n",
       "poetri               0           1           0\n",
       "precis               0           1           0\n",
       "shape                0           0           1\n",
       "solv                 0           1           0\n",
       "teach                0           1           0\n",
       "text                 1           0           0\n",
       "thrive               0           0           1\n",
       "tongu                0           1           0\n",
       "translat             1           0           0\n",
       "ultim                1           0           0\n",
       "understand           0           0           1\n",
       "understood           0           0           1\n",
       "voic                 1           0           1\n",
       "voiceless            1           0           0\n",
       "word                 0           0           1\n",
       "world                1           0           1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "paragraph = \"\"\"\n",
    "In a world where language became the ultimate bridge, \n",
    "NLP emerged as humanity's greatest ally, \n",
    "decoding ancient texts, translating cultures, and even giving voice to the voiceless. \n",
    "\n",
    "As algorithms learned to empathize, crafting poetry, \n",
    "solving conflicts, and teaching forgotten tongues, \n",
    "they blurred the line between human creativity and machine precision.\n",
    "\n",
    "The future no longer feared miscommunication; instead, it thrived on understanding, \n",
    "with NLP not just interpreting words but shaping a world where every voice, \n",
    "in any language, could be heard, understood, and celebrated.\n",
    "\"\"\"\n",
    "sentences = nltk.sent_tokenize(paragraph)\n",
    "\n",
    "# Step 2: Preprocessing each sentence\n",
    "ps = PorterStemmer()\n",
    "corpus = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    # Remove special characters, numbers, and punctuations\n",
    "    review = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()\n",
    "    # Split into words\n",
    "    review = review.split()\n",
    "    # Remove stopwords and apply stemming\n",
    "    review = [ps.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    # Join the words back into a sentence\n",
    "    review = ' '.join(review)\n",
    "    # Add the cleaned sentence to the corpus\n",
    "    corpus.append(review)\n",
    "\n",
    "# Step 3: Create Bag of Words model\n",
    "cv = CountVectorizer(max_features=1500)  # Limit to top 1500 features (if necessary)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "\n",
    "# Get feature names (vocabulary)\n",
    "vocabulary = cv.get_feature_names_out()\n",
    "\n",
    "# Create DataFrame with each sentence as a column\n",
    "bow_df = pd.DataFrame(X.T, index=vocabulary, columns=[f\"Document {i+1}\" for i in range(X.shape[0])])\n",
    "bow_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Term Frequency-Inverse Document Frequency (`TF-IDF`)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pointwise Mutual Information (`PMI`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Closing Thoughts "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
