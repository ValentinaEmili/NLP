{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "### 2.2 Scaling word2vec and introduction to Neural Nets for NLP\n",
    "<br><br>\n",
    "Prof. Iacopo Masi and Prof. Stefano Faralli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.colheader_justify', 'center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hide_input": true,
    "run_control": {
     "marked": false
    },
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "font = {'family' : 'Times',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "\n",
    "# Aux functions\n",
    "\n",
    "def plot_grid(Xs, Ys, axs=None):\n",
    "    ''' Aux function to plot a grid'''\n",
    "    t = np.arange(Xs.size) # define progression of int for indexing colormap\n",
    "    if axs:\n",
    "        axs.plot(0, 0, marker='*', color='r', linestyle='none') #plot origin\n",
    "        axs.scatter(Xs,Ys, c=t, cmap='jet', marker='.') # scatter x vs y\n",
    "        axs.axis('scaled') # axis scaled\n",
    "    else:\n",
    "        plt.plot(0, 0, marker='*', color='r', linestyle='none') #plot origin\n",
    "        plt.scatter(Xs,Ys, c=t, cmap='jet', marker='.') # scatter x vs y\n",
    "        plt.axis('scaled') # axis scaled\n",
    "        \n",
    "def linear_map(A, Xs, Ys):\n",
    "    '''Map src points with A'''\n",
    "    # [NxN,NxN] -> NxNx2 # add 3-rd axis, like adding another layer\n",
    "    src = np.stack((Xs,Ys), axis=Xs.ndim)\n",
    "    # flatten first two dimension\n",
    "    # (NN)x2\n",
    "    src_r = src.reshape(-1,src.shape[-1]) #ask reshape to keep last dimension and adjust the rest\n",
    "    # 2x2 @ 2x(NN)\n",
    "    dst = A @ src_r.T # 2xNN\n",
    "    #(NN)x2 and then reshape as NxNx2\n",
    "    dst = (dst.T).reshape(src.shape)\n",
    "    # Access X and Y\n",
    "    return dst[...,0], dst[...,1]\n",
    "\n",
    "\n",
    "def plot_points(ax, Xs, Ys, col='red', unit=None, linestyle='solid'):\n",
    "    '''Plots points'''\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid(True, which='both')\n",
    "    ax.axhline(y=0, color='gray', linestyle=\"--\")\n",
    "    ax.axvline(x=0, color='gray',  linestyle=\"--\")\n",
    "    ax.plot(Xs, Ys, color=col)\n",
    "    if unit is None:\n",
    "        plotVectors(ax, [[0,1],[1,0]], ['gray']*2, alpha=1, linestyle=linestyle)\n",
    "    else:\n",
    "        plotVectors(ax, unit, [col]*2, alpha=1, linestyle=linestyle)\n",
    "\n",
    "def plotVectors(ax, vecs, cols, alpha=1, linestyle='solid'):\n",
    "    '''Plot set of vectors.'''\n",
    "    for i in range(len(vecs)):\n",
    "        x = np.concatenate([[0,0], vecs[i]])\n",
    "        ax.quiver([x[0]],\n",
    "                   [x[1]],\n",
    "                   [x[2]],\n",
    "                   [x[3]],\n",
    "                   angles='xy', scale_units='xy', scale=1, color=cols[i],\n",
    "                   alpha=alpha, linestyle=linestyle, linewidth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## My own latex definitions\n",
    "\n",
    "$$\\def\\mbf#1{\\mathbf{#1}}$$\n",
    "$$\\def\\bmf#1{\\boldsymbol{#1}}$$\n",
    "$$\\def\\bx{\\mbf{x}}$$\n",
    "$$\\def\\bxt#1{\\mbf{x}_{\\text{#1}}}$$\n",
    "$$\\def\\bv{\\mbf{v}}$$\n",
    "$$\\def\\bz{\\mbf{z}}$$\n",
    "$$\\def\\bmu{\\bmf{\\mu}}$$\n",
    "$$\\def\\bsigma{\\bmf{\\Sigma}}$$\n",
    "$$\\def\\Rd#1{\\in \\mathbb{R}^{#1}}$$\n",
    "$$\\def\\chain#1#2{\\frac{\\partial #1}{\\partial #2}}$$\n",
    "$$\\def\\loss{\\mathcal{L}}$$\n",
    "$$\\def\\params{\\bmf{\\theta}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today's lecture\n",
    "## - Skip-Gram and Continuous Bag of Words (CBOW)\n",
    "## - How to scale word2vec\n",
    "### - Negative Sampling\n",
    "### - Hierarchical Softmax\n",
    "## - Introduction to Neural Nets for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This lecture material is taken from\n",
    "üìò **Chapter 6 Jurafsky Book**\n",
    "\n",
    "üìò **Chapter 14.5 Eisenstein Book**\n",
    "- [Stanford Slide Word2Vec](http://web.stanford.edu/class/cs224n/slides/cs224n-2022-lecture01-wordvecs2.pdf)\n",
    "- [Stanford Lecture Word2Vec](https://www.youtube.com/watch?v=rmVRLeJRkl4&list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&index=1)\n",
    "- [Stanford Notes on Word2Vec](http://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes01-wordvecs1.pdf)\n",
    "\n",
    "Another good yet short resource is [[d2l.ai] Word embedding](https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html)\n",
    "\n",
    "üìù Research papers on word2vec and hierarchical softmax:\n",
    "- [First paper: word2vec + hierarchical softmax](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "- [Negative Sampling paper](https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf)\n",
    "- [A Scalable Hierarchical Distributed Language Model](http://papers.nips.cc/paper/3583-a-scalable-hierarchical-distributed-language-model.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec is a generic framework \n",
    "\n",
    "`word2vec` presents two algorithms:\n",
    " 1. ~~Skip-Gram~~\n",
    " 2. **Continuous Bag-of-Word** (CBOW)  _(we see it today!)_\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br><br>\n",
    "\n",
    "Also it offers different training methods:\n",
    " - ~~with naive softmax~~  \n",
    " - **negative sampling** from [Mikolov et al. 2013]\n",
    " - **hierarchical softmax** _(we see them today!)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec: Skip-Gram Self-Supervision\n",
    "\n",
    "‚ö†Ô∏è With **strong naive conditional independence assumption** \n",
    "<br/>\n",
    "\n",
    "$$ p(w_{t-2},w_{t-1},w_{t+1},w_{t+2}|w_t;\\bmf{\\theta}) \\approx \\prod_{-m\\leq j\\leq m}^m p(c_{t+j}|w_t;\\bmf{\\theta})$$\n",
    "\n",
    "<br/>\n",
    "\n",
    "|   | ~~lemon~~, | ~~a~~ | [tablespoon | of | apricot | jam | a] | ~~pinch~~ |\n",
    "|:-:|:------:|:-:|:-----------:|:--:|:-------:|:---:|:--:|:-----:|\n",
    "|   |        |   |      w_{t-2}     | w_{t-1} |    **$w_t$**    |  w_{t+1} | w_{t+2} |       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec: Skip-Gram Self-Supervision\n",
    "\n",
    "Given the example below, we have to compute:\n",
    "<br/>\n",
    "\n",
    "$$p(w_{t-2}|w_t)\\cdot p(w_{t-1}|w_t)\\cdot p(w_{t+1}|w_t)\\cdot p(w_{t+2}|w_t)$$\n",
    "<br/><br/>\n",
    "<div align='center'><img src=\"figs/word2vec_skipgram.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec: Skip-Gram with softmax\n",
    "\n",
    "Parameters to learn: $$\\bmf{\\theta} = [\\bmf{\\theta}_W;\\bmf{\\theta}_C]$$\n",
    "\n",
    "<div align='center'><img src=\"figs/word2vec_params.png\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec with Skip-Gram at a glance\n",
    "\n",
    "... and why it can be seen as a tiny neural net.\n",
    "\n",
    "<div align='center'><img src=\"figs/word2vec_layers.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss function: compare two discrete distributions\n",
    " \n",
    "$$\\mbf{p}=\\operatorname{softmax}\\big(\\bmf{\\theta}_C\\cdot\\bmf{\\theta}_{W}[i]^T\\big) $$\n",
    "\n",
    "You can think $\\mbf{p}$ as of this form:\n",
    "\n",
    "|    \t| lemon   \t| tablespoon \t| gelato             \t| ...\t | jam\t|\n",
    "|----------|----------\t|--------\t|--------------------\t|--------\t|--------\t|\n",
    "|**p (word2vec prediction)**        | 0.001 | 0.1 | 0.03  | ... | 0.15 |\n",
    "\n",
    "\n",
    "Let's consider the label as a one-hot encoding vector where 1 is over the ground-truth word given by the text.\n",
    "\n",
    "|    \t| lemon   \t| tablespoon \t| gelato             \t| ...\t | jam\t|\n",
    "|----------|----------\t|--------\t|--------------------\t|--------\t|--------\t|\n",
    "|**y label (ground-truth $w_{t-1}$)** | 0 | 1 | 0  | ... | 0 |\n",
    "\n",
    "### We want to adjust the weights $\\bmf{\\theta}$ so that $\\mbf{p}$ matches the label!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# One-hot encoding is a selector!\n",
    "\n",
    "\n",
    "- $\\mbf{y}=[0,0,0,1,0]$ $\\rightarrow$ works as a selector of probability of the actual ground-truth word that we removed!\n",
    "- Of the probabilites returned by `word2vec` select that for which the index $gt$ corresponds to the `1` in the label $\\mbf{y}$\n",
    "- in our case, $gt$ is the index of `tablespoon` in $|V|$.\n",
    "\n",
    "$$ \\mathcal{L}(w_{t-1},w_{t};\\mbf{\\theta}) = -\\log \\big[\\mbf{p}\\big(w_{t-1}|w_{t}\\big)\\big]{[gt]}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss function simplified\n",
    "\n",
    "We can select immediately $[gt]$ in the numerator.\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w_{t-1},w_{t};\\mbf{\\theta}) = -\\log \\left(\\frac{\\exp \\big( \\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T \\big)}{\\sum_{v=1}^{V} \\exp \\big(\\bmf{\\theta}_{C}[v]\\cdot\\bmf{\\theta}_{W}[i]^T\\big)}\\right)\n",
    "$$\n",
    "\n",
    "Sometimes is shown as:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w_{t-1},w_{t};\\mbf{\\theta}) = \\underbrace{-\\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T}_{\\text{similarity center vs context}} + \\underbrace{\\log\\Big(\\sum_{v=1}^{V} \\exp \\big(\\bmf{\\theta}_{C}[v]\\cdot\\bmf{\\theta}_{W}[i]^T\\big)\\Big)}_{\\text{make sure it is a probability}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# word2vec: Continuous Bag-of-Word (C-BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Skip-Gram\n",
    "\n",
    "$$ p(w_{t-2},w_{t-1},w_{t+1},w_{t+2}|w_t;\\bmf{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# C-BOW\n",
    "\n",
    "$$ p(w_t|w_{t-2},w_{t-1},w_{t+1},w_{t+2};\\bmf{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec: C-BOW\n",
    "\n",
    "Given the context $w_{t-2},w_{t-1},w_{t+1},w_{t+2} \\longrightarrow p(w_t)$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "|   | ~~lemon~~, | ~~a~~ | [tablespoon | of | ----?---| jam | a] | ~~pinch~~ |\n",
    "|:-:|:------:|:-:|:-----------:|:--:|:-------:|:---:|:--:|:-----:|\n",
    "|   |        |   |      w_{t-2}     | w_{t-1} |    **$w_t$**    |  w_{t+1} | w_{t+2} |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# word2vec: Continuous Bag-of-Word (CBOW)\n",
    "\n",
    "$$w_{t-2},w_{t-1},w_{t+1},w_{t+2} \\longrightarrow p(w_t)$$<br>\n",
    " \n",
    "$$\\bmf{\\theta}_{C_{avg}} = \\sum_{-m\\leq j\\leq m,~j \\neq 0} \\bmf{\\theta}_{C}[t+j]$$\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/word2vec_cbow.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec: Continuous Bag-of-Word (CBOW)\n",
    "\n",
    "<div align='center'><img src=\"figs/word2vec_layers_cbow.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to compute $p(w_{t-1}|w_{avg})$?\n",
    "1. $\\bmf{\\theta}_{C_{avg}}$ is the average embedding from the context parameters $\\bmf{\\theta}_{C}$. The average is computed once defined the context window size.\n",
    "\n",
    "$$\\underbrace{\\mbf{z}}_{|V|\\times 1}=\\overbrace{\\underbrace{\\bmf{\\theta}_C}_{|V|\\times D}}^{\\text{as center}}\\cdot\\overbrace{\\underbrace{\\bmf{\\theta}_{C_{avg}}^T}_{D\\times 1}}^{\\text{as context}} $$\n",
    "\n",
    "2. $\\mbf{z}$ is logits and encodes the similarity via dot product of the average context word embedding $\\bmf{\\theta}_{C_{avg}}$ **against all vocabulary words** taken as center $\\bmf{\\theta}_C$\n",
    "\n",
    "3. We pass $\\mbf{z}$ through softmax operator to get a distribution over $|V|$ as: $$\\mbf{p}=\\operatorname{softmax}(\\mbf{z}) $$\n",
    "\n",
    "You can think $\\mbf{p}$ as of this form:\n",
    "\n",
    "|    \t| lemon   \t| tablespoon \t| gelato             \t| ...\t | jam\t|\n",
    "|----------|----------\t|--------\t|--------------------\t|--------\t|--------\t|\n",
    "|**p** | 0.001 | 0.1 | 0.03  | ... | 0.15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Skipgram vs CBOW at a glance\n",
    "\n",
    "<div align='center'><img src=\"figs/skip_vs_cbow.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Computational Complexity\n",
    "\n",
    "- word2vec computes a **normalized probability over\n",
    "word tokens (over the vocabulary $V$)**\n",
    "- A naive  implementation of this probability requires <ins>summing over the entire vocabulary $V$</ins>\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w_{t-1},w_{t};\\mbf{\\theta}) = -\\log \\left(\\frac{\\exp \\big( \\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T \\big)}{\\sum_{v=1}^{V} \\exp \\big(\\bmf{\\theta}_{C}[v]\\cdot\\bmf{\\theta}_{W}[i]^T\\big)}\\right)\n",
    "$$\n",
    "\n",
    "The normalization in the denominator is of the order of: $$ \\mathcal{O}(|V|\\times D)$$ where:\n",
    "- $|V|$ is the vocabulary size and e.g. $|V|=3M$ \n",
    "- $D$ is the dimension of the embeddings e.g. $D=300$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Two solutions to approximate the denominator\n",
    "\n",
    "\n",
    "1. Negative sampling (Contrastive method)\n",
    "2. Hierarchical Softmax (Tree-based solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling word2vec with Negative Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Skip-gram with Negative Sampling (SGNS)\n",
    "\n",
    "Instead of doing:\n",
    "\n",
    "1. **Center word vs ground-truth context embedding** $\\longrightarrow \\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T$\n",
    "2. normalize as a distribution: **all context vs center word** $\\longrightarrow \\sum_{v=1}^{V} \\exp \\big(\\bmf{\\theta}_{C}[v]\\cdot\\bmf{\\theta}_{W}[i]^T\\big)$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(w_{t-1},w_{t};\\mbf{\\theta}) = \\underbrace{-\\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T}_{\\text{similarity center vs context}} + \\underbrace{\\log\\Big(\\sum_{v=1}^{V} \\exp \\big(\\bmf{\\theta}_{C}[v]\\cdot\\bmf{\\theta}_{W}[i]^T\\big)\\Big)}_{\\text{make sure it is a probability}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Skip-gram with Negative Sampling (SGNS)\n",
    "\n",
    "We \"relax\" the denominator and do:\n",
    "\n",
    "1. _[Same as before]_ **Center word vs ground-truth context embedding** $\\longrightarrow \\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T$\n",
    "2. Approximate the denominator as:\n",
    " - Sample a $k$ context words from $V$.\n",
    " - Compare **each $k$-th sampled word vs center word**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Negative Sampling is a form of Contrastive Method\n",
    "\n",
    "<br><div align='center'><img src=\"figs/word2vec_contrastive.png?1\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Negative Sampling is a form of Contrastive Method\n",
    "\n",
    "- **Positive Constraint:**\n",
    "    - Pull $\\bmf{\\theta}_{C}[gt]$ and $\\bmf{\\theta}_{W}$ to be \"close\" in space (give high dot-product score)\n",
    "    - Center and ground-truth context need to have high similarity\n",
    "    - In doing so we may make other words unrelated to be close in the space, so **we have to push them away**\n",
    "- **Negative Constraint:**\n",
    "    - We have to push away $\\bmf{\\theta}_{W}$ for any other remaining $\\bmf{\\theta}_{C}[i] \\quad \\forall i \\in V, i \\neq gt$ \n",
    "    - Before, this was done by forcing the total \"mass\" over the vocabulary distribution to sum to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Consider the simplified case: a center vs a context word\n",
    "\n",
    "<br><div align='center'><img src=\"figs/word2vec_negative_onesample.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Skip-gram with Negative Sampling (SGNS)\n",
    "\n",
    "- Given $w_t$ the center word and $w_{t-2}$ the context word to be predicted; \n",
    "- Assuming $gt$ is the index of $w_{t-2}$ in $V$ and $i$ is the index of $w_t$ in $V$: \n",
    "<br><br>\n",
    "1. **[Positive] Center word vs ground-truth context embedding** $\\longrightarrow \\bmf{\\theta}_{C}[gt]\\cdot\\bmf{\\theta}_{W}[i]^T$\n",
    "2. **[Negative]** Sample $k$ negative indexes $v$ from $V$ such that: $v \\in V, v \\neq gt$\n",
    "\n",
    "### Dot Products:\n",
    "$$ \\underbrace{1}_{\\text{positive; center vs context}} ~~~\\text{vs}~~~ \\underbrace{k}_{\\text{negative; center vs non-context}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Skip-gram with Negative Sampling (SGNS) over a window\n",
    "- Window size is $m=2$ ($m$ is one side of the window, so total context words are $2m$)\n",
    "- Number of negative $k=2$\n",
    "\n",
    "|   | ~~lemon~~, | ~~a~~ | [tablespoon | of | apricot| jam | a] | ~~pinch~~ |\n",
    "|:-:|:------:|:-:|:-----------:|:--:|:-------:|:---:|:--:|:-----:|\n",
    "|   |        |   |      w_{t-2}     | w_{t-1} |    **$w_t$**    |  w_{t+1} | w_{t+2} |       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br>\n",
    "<div align='center'><img src=\"figs/positive.png\" width='35%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br>\n",
    "<div align='center'><img src=\"figs/negative.png\" width='55%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# so, how do we model that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# From global softmax to binary classification for each pair\n",
    "\n",
    "Recall: words are assumed all conditionally independent [it is not true in pratice!]\n",
    "\n",
    "1. We instantiate a **binary classifier as Logistic Regression** (same as softmax but just two classes, either positive pair $y=+1$ or negative pair $y=0$)\n",
    "2. We use the sigmoid function $\\bmf{\\sigma}$ to map the dot-product result to a probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Binary Logistic Regression\n",
    "\n",
    "\n",
    "$$f_{\\boldsymbol{\\theta}}(\\mbf{x}) \\doteq \\sigma\\left(  \\bmf{\\theta}^T\\mbf{x} \\right)$$\n",
    "\n",
    "where:\n",
    "\n",
    "$$ \\sigma(z)= \\frac{1}{1+\\exp^{-z}} \\quad \\text{sigmoid or logistic function}$$\n",
    "\n",
    "Other important properties:\n",
    "\n",
    "$$\\sigma(z)= \\frac{\\exp^{z}}{1+\\exp^{z}}; \\quad \\sigma(z)= 1-\\sigma(-z) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    },
    "variables": {
     "import numpy as np;import matplotlib.pyplot as plt;x = np.arange(-20.0, 20.0, 0.1);y = 1/(1+np.exp(-x));_=plt.plot(x,y);": "<img src=\"data:image/png;base64,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\n\"/>"
    }
   },
   "source": [
    "<br><br> <center>Smooth and Differentiable alternative to sign</center>\n",
    "{{import numpy as np;import matplotlib.pyplot as plt;x = np.arange(-20.0, 20.0, 0.1);y = 1/(1+np.exp(-x));_=plt.plot(x,y);}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Likelihood with negative sampling\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/word2vec_negative_onesample.png\" width='45%' ></div>\n",
    "<br>\n",
    "$$ \\max_{\\params} \\underbrace{p(y=+1|w_{t-1},w_t;\\params)}_{\\text{pos. center vs context}}\\cdot \\underbrace{\\prod_{k=1}^K p(y=0|w_k,w_t;\\params)}_{\\text{neg. center vs k samples}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Likelihood with negative sampling\n",
    "\n",
    "$$ \\max_{\\params} \\underbrace{p(y=+1|w_{t-1},w_t;\\params)}_{\\text{pos. center vs context}}\\cdot \\underbrace{\\prod_{k=1}^K p(y=0|w_k,w_t;\\params)}_{\\text{neg. center vs k samples}}$$\n",
    "\n",
    "We can apply $\\log$ since is strictly monotonic, will not change the optimization:\n",
    "\n",
    "$$ \\max_{\\params} \\log p(y=+1|w_{t-1},w_t;\\params)+ \\log \\sum_{k=1}^K p(y=0|w_k,w_t;\\params)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\max_{\\params} \\log p(y=+1|w_{t-1},w_t;\\params)+ \\log \\sum_{k=1}^K \\underbrace{1- p(y=+1|w_k,w_t;\\params)}_{\\text{it is a binary classifier!}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Likelihood with negative sampling\n",
    "\n",
    "$$ \\max_{\\params} \\log p(y=+1|w_{t-1},w_t;\\params)+  \\sum_{k=1}^K \\log\\big[1- p(y=+1|w_k,w_t;\\params)\\big]$$\n",
    "\n",
    "We replace $p(\\cdot)$ with the logistic regression and using $\\sigma(-z)= 1-\\sigma(z)$, we get:\n",
    "\n",
    "$$ \\max_{\\params} \\log \\sigma \\left(\\params_{C}[gt]^T\\params_W[i]\\right)+ \\sum_{k=1}^K \\log \\big[ \\sigma\\left(-\\params_{C}[k]^T\\params_W[i]\\right)\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss with negative sampling\n",
    "\n",
    "If we minimize, we have to invert the sign:\n",
    "\n",
    "$$ \\min_{\\params} -\\log \\sigma \\left(\\params_{C}[gt]^T\\params_W[i]\\right) - \\sum_{k=1}^K \\log \\big[ \\sigma\\left(-\\params_{C}[k]^T\\params_W[i]\\right)\\big]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Visualization\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"figs/negative_params.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to sample the negatives\n",
    "\n",
    "Which is, how to select the indexes $k \\in \\{1\\ldots K\\}, k \\neq gt$ in $\\sum_{k=1}^K \\log \\big[ \\sigma\\left(-\\params_{C}[k]^T\\params_W[i]\\right)\\big]$ ?\n",
    "\n",
    "We sample from an **Unigram model** defined over the corpus $V$ as:\n",
    "\n",
    "$$ P(v)_{\\alpha} = \\frac{\\operatorname{count(v)^\\alpha}}{\\sum_{v^{\\prime}}\\operatorname{count(v^{\\prime})^\\alpha}}$$\n",
    "and fixing $\\alpha=\\frac{3}{4}=0.75$\n",
    "\n",
    "<br>\n",
    "Setting $\\alpha=0.75$ gives better performance because <b>gives rare noise words slightly\n",
    "higher probability.</b> For rare words, $P(v)_{\\alpha} > P(v)$ while <b>common words are more or less kept the same.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to sample the negatives\n",
    "\n",
    "$$ P(v)_{\\alpha} = \\frac{\\operatorname{count(v)^\\alpha}}{\\sum_{v^{\\prime}}\\operatorname{count(v^{\\prime})^\\alpha}}$$\n",
    "and fixing $\\alpha=\\frac{3}{4}=0.75$\n",
    "<br><br>\n",
    "**Example:**\n",
    "$$\\text{is:} \\quad {0.9}^{.75} = 0.92\\\\\n",
    "\\text{Constitution:} \\quad {0.09}^{.75} = 0.16\\\\\n",
    "\\text{bombastic:} \\quad 0.01^{.75} = 0.032$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sparse Gradients\n",
    "\n",
    "- We iteratively take gradients at each window for SGD\n",
    "- In each window, we only have at most $2m + 1$ words plus $2km$ negative words with negative sampling, so the gradient over a window $\\nabla_{\\params}\\mathcal{L}_t({\\params})$ is very sparse!\n",
    "- Computationally, it is important to not have to send gigantic updates around.\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta \\mathcal{L}(\\theta)=\\left[\\begin{array}{l}\n",
    "\\mbf{0} \\\\\n",
    "\\vdots \\\\\n",
    "\\nabla_{\\params_W{_{l i k e}}} \\\\\n",
    "\\vdots \\\\\n",
    "\\mbf{0} \\\\\n",
    "\\nabla_{\\params_W{_{am}}} \\\\\n",
    "\\vdots \\\\\n",
    "\\nabla_{\\params_W{_{learning}}} \\\\\n",
    "\\vdots\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{2 d V}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scaling word2vec with Hierarchical Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hierarchical Softmax in NLP\n",
    "\n",
    "It is an alternative to **Negative Sampling.** We do not use a contrastive method yet we approximate the normalization over the large vocabulary with a **balanced binary tree structure**.\n",
    "\n",
    "Computational cost reduces from $\\mathcal{O} \\big( |V| \\big)$ to $\\mathcal{O}\\big(\\log_2(|V|)\\big)$ **in the best case.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Regular Softmax is a degenerate tree!\n",
    "\n",
    "We change point of view: softmax is a tree of depth=1 and $|V|$ children that are leaf too!\n",
    "\n",
    "Corpus `this is an example of a huffman tree` and assume <ins>**word tokens are characters** to simplify.</ins>\n",
    "<br><br>\n",
    "<div align='center'><img src=\"figs/softmax_tree_linear.png\" width='45%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Hierarchical Softmax in NLP\n",
    "\n",
    "1. Given a vocabulary of word token $V$ how to construct the tree (there are multiple ways of doing it)\n",
    "2. How to train with the tree\n",
    "3. How to perform inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Huffman tree\n",
    "\n",
    "Given a vocabulary of word token $V$ how to construct the tree? We use **Huffman trees**\n",
    "\n",
    "The corpus is `this is an example of a huffman tree` and assume <ins>**word tokens are characters** to simplify.</ins>\n",
    "\n",
    "| **chars** | **e** | **a** | **n** | **t** | **m** | **o** | **u** | **i** | **h** | **s** | **x** | **p** | **' '** | **f** | **r** | **l** |\n",
    "|-----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|---------|-------|-------|-------|\n",
    "| **freq**  | 4     | 4     | 2     | 2     | 2     | 1     | 1     | 2     | 2     | 2     | 1     | 1     | 7       | 3     | 1     | 1     |\n",
    "\n",
    "<div align='center'><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Huffman_tree_2.svg/938px-Huffman_tree_2.svg.png\" width='35%' ></div>\n",
    "\n",
    "<small>picture from Wikipedia</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Huffman tree\n",
    "\n",
    "- vocabulary $V \\rightarrow$ word frequencies with **Unigram model.**\n",
    "- More frequent word tokens are placed closer to the root; rare words are at deeper layers.\n",
    "    - If you think Information Theory, we \"spend\" less in encoding frequent words and each word has a variable code length.\n",
    "    - We want to encode `'e'` with a bit string. Convention: left is `0` and right is `1`\n",
    "    -  Then encoding of `'e'` is `left->left->left` which is `000` 3 bits\n",
    "    - Yet the encoding of `'p'` is `right->left->left->right->right` which is `10011` 5 bits\n",
    "- Each node has always two children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Huffman tree\n",
    "\n",
    "| **chars** | **e** | **a** | **n** | **t** | **m** | **o** | **u** | **i** | **h** | **s** | **x** | **p** | **' '** | **f** | **r** | **l** |\n",
    "|-----------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|-------|---------|-------|-------|-------|\n",
    "| **freq**  | 4     | 4     | 2     | 2     | 2     | 1     | 1     | 2     | 2     | 2     | 1     | 1     | 7       | 3     | 1     | 1     |\n",
    "\n",
    "<br><br>\n",
    "<div align='center'><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Huffman_tree_2.svg/938px-Huffman_tree_2.svg.png\" width='55%' ></div>\n",
    "\n",
    "<small>picture from Wikipedia</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training with Hierarchical Softmax\n",
    "\n",
    "We do not model anymore $\\params$ as the number of words in $V$, yet we model $\\params$ as the number of internal nodes in the tree $V-1$.\n",
    "\n",
    "We have a feature vector to be learned at each node $i$ of the tree for a total of $2V-1$ vectors to be learned (context and center).\n",
    "\n",
    "We assume Skip-gram and we want to compute $p(w_{t-1}|w_t = \\text{natural})$; we also assume the ground-truth $w_{t-1}$ is language.\n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_1.png\" width='35%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training with Hierarchical Softmax\n",
    "\n",
    "Assume Skip-gram and we want to compute $p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "So we \"bypass\" all paths except the one that from root leads to `language`.\n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_2.png\" width='35%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is \"language\". \n",
    "\n",
    "$$p(w_{t-1}|w_t = \\text{natural}) = \\prod_{n~\\in~path(\\text{root}\\rightarrow \\text{language})} p_{\\operatorname{branch}}\\big(n,i\\big)$$\n",
    "\n",
    "where: \n",
    "$$ \n",
    "p_{\\operatorname{branch}}(n,i) = \\begin{cases} \\sigma\\big(\\boldsymbol{\\theta}_C[n]^T\\boldsymbol{\\theta}_W[i])\\big), & \\mbox{if } \\mbox{left} \\\\ \n",
    "1-\\sigma\\big(\\boldsymbol{\\theta}_C[n]^T\\boldsymbol{\\theta}_W[i])\\big), & \\mbox{if } \\mbox{right} \\end{cases} \n",
    "$$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div align='center'><img src=\"figs/hsoftmax_3.png?2\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3a.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/hsoftmax_3b.png?2\" width='75%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Embeddings as a Matrix\n",
    "\n",
    "The embedding $\\params_C$ are still in a matrix, where each row of the matrix is indexed by the node $n$ index.\n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_matrix.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3b.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3c.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3d.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3e.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3f.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural})$ and we assume the ground-truth $w_{t-1}$ is language. \n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3g.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise: compute the loss with Hierarchical Softmax\n",
    "\n",
    "$p(w_{t-1}|w_t = \\text{natural}) = 1 \\cdot 0.9\\cdot0.95\\cdot0.65\\cdot0.2 = 0.11115$\n",
    "\n",
    "Loss is $-\\log\\big(p(w_{t-1}|w_t = \\text{natural})\\big) = -\\log(0.11115)$\n",
    "\n",
    "<div align='center'><img src=\"figs/hsoftmax_3g.png?2\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Inference with Hierarchical Softmax\n",
    "\n",
    "**Important:** In inference with do not have the label!\n",
    "\n",
    "1. Exhaustive search [too complex]\n",
    "2. Greedy search (at each branch take the branch at maximum probability) [too greedy]\n",
    "3. **Beam search** (we will cover later on)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Google Allo project used Beam search/Hierarchical Softmax\n",
    "Google (now dead ‚ò†Ô∏è ) project Allo used a Hierarchical tree to speed up inference.\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/allo_2016.png\" width='35%' ></div>\n",
    "\n",
    "<small>Taken from https://ai.googleblog.com/2016/05/chat-smarter-with-allo.html</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Google Allo project used Beam search/Hierarchical Softmax\n",
    "\n",
    "Google (now dead ‚ò†Ô∏è ) project Allo used a Hierarchical tree to speed up inference.\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/allo_2016_beam_search.png\" width='45%' ></div>\n",
    "\n",
    "<small>Taken from https://ai.googleblog.com/2016/05/chat-smarter-with-allo.html</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Google Allo project used Hierarchical Softmax\n",
    "\n",
    "> As with any large-scale product, there were several engineering challenges we had to solve in generating a set of high-quality responses efficiently. For example, in spite of the two staged architecture, our first few networks were very slow and required about half a second to generate a response. This was obviously a deal breaker when we are talking about real time communication apps! \n",
    "\n",
    "> So we had to evolve our neural network architecture further to reduce the latency to less than 200ms. We moved from using **a softmax layer to a hierarchical softmax layer which traverses a tree of words instead of traversing a list of words thus making it more efficient.**\n",
    "\n",
    "<small>Taken from https://ai.googleblog.com/2016/05/chat-smarter-with-allo.html</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hints on fastText\n",
    "\n",
    "<div align='center'><img src=https://radimrehurek.com/gensim/_images/sphx_glr_run_fasttext_001.png width='25%' ></div>\n",
    "\n",
    "- Morphological structure of a word carries important information about the meaning of the word.\n",
    "\n",
    "- fastText attempts to solve this by treating each word as the aggregation of its subwords.\n",
    "- Morphologically rich languages (German, Turkish) in which a single word can have a large number of morphological forms, each of which might occur rarely, thus making it hard to train good word embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "# Subword Embedding\n",
    "\n",
    "In English,\n",
    "words such as\n",
    ">\"helps\", \"helped\", and \"helping\" are \n",
    "\n",
    "inflected forms of the same word \"help\".\n",
    "The relationship \n",
    "between \"dog\" and \"dogs\"\n",
    "is the same as \n",
    "that between \"cat\" and \"cats\",\n",
    "and \n",
    "the relationship \n",
    "between \"boy\" and \"boyfriend\"\n",
    "is the same as \n",
    "that between \"girl\" and \"girlfriend\".\n",
    "\n",
    "In other languages\n",
    "such as French and Spanish,\n",
    "**many verbs have over 40 inflected forms,**\n",
    "while in Finnish,\n",
    "a noun may have up to 15 cases.\n",
    "\n",
    "In linguistics,\n",
    "morphology studies word formation and word relationships.\n",
    "However,\n",
    "the internal structure of words\n",
    "was neither explored in word2vec\n",
    "nor in GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The fastText Model\n",
    "\n",
    "To use morphological information,\n",
    "the *fastText* model\n",
    "proposed a *subword embedding* approach,\n",
    "where a **subword is a character $n$-gram**.\n",
    "\n",
    "Instead of learning word-level vector representations,\n",
    "fastText can be considered as\n",
    "the **subword-level skip-gram**,\n",
    "where each *center word* is represented by the sum of \n",
    "its subword vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The fastText Model\n",
    "\n",
    "Let's illustrate how to obtain \n",
    "subwords for each center word in fastText\n",
    "using the word \"where\".\n",
    "First, add special characters ‚Äú&lt;‚Äù and ‚Äú&gt;‚Äù \n",
    "at the beginning and end of the word to distinguish prefixes and suffixes from other subwords. \n",
    "Then, extract character $n$-grams from the word.\n",
    "For example, when $n=3$,\n",
    "we obtain all subwords of length 3: \"&lt;wh\", \"whe\", \"her\", \"ere\", \"re&gt;\", and the special subword \"&lt;where&gt;\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In fastText, for any word $w$,\n",
    "denote by $\\mathcal{G}_w$\n",
    "the union of all its subwords of length between 3 and 6\n",
    "and its special subword.\n",
    "The vocabulary \n",
    "is the union of the subwords of all words.\n",
    "Letting $\\mathbf{z}_g$\n",
    "be the vector of subword $g$ in the dictionary,\n",
    "the vector $\\mathbf{v}_w$ for \n",
    "word $w$ as a center word\n",
    "in the skip-gram model\n",
    "is the sum of its subword vectors:\n",
    "\n",
    "$$\\mathbf{v}_w = \\sum_{g\\in\\mathcal{G}_w} \\mathbf{z}_g.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The rest of fastText is the same as the skip-gram model. Compared with the skip-gram model, \n",
    "**the vocabulary in fastText is larger,**\n",
    "resulting in **more model parameters.**\n",
    "Besides, \n",
    "to calculate the representation of a word,\n",
    "all its subword vectors\n",
    "have to be summed,\n",
    "leading to higher computational complexity.\n",
    "**However,\n",
    "thanks to shared parameters from subwords among words with similar structures,\n",
    "rare words and even out-of-vocabulary words\n",
    "may obtain better vector representations in fastText.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Evaluating Word Embeddings\n",
    "\n",
    "Related to general evaluation in NLP/Machine Learning: **Intrinsic vs. Extrinsic**\n",
    "\n",
    "- **Intrinsic**:\n",
    "\t- Evaluation on a specific/intermediate subtask\n",
    "\t- Fast to compute\n",
    "\t- Helps to understand that system\n",
    "\t- Not clear if really helpful unless correlation to real task is established\n",
    "    - Often involve **correlation with human judgments**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- **Extrinsic**:\n",
    "\t- Evaluation on a real downstream task\n",
    "\t- Can take a long time to compute accuracy\n",
    "\t- Unclear if the subsystem is the problem or its interaction or other subsystems\n",
    "\t- If replacing exactly one subsystem with another improves accuracy $\\rightarrow$ Winner! **(Ablation study)**\n",
    "\t- Always perform validation of the hyper-parameter on a validation (or dev) set; when you are sure then test once.\n",
    "\n",
    "<small>Taken from cs224n Stanford NLP with Deep learning</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Embedding and Historical Semantics\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/historical.png\" width='65%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Bias and Embeddings ‚ö†Ô∏è\n",
    "\n",
    "In addition to their ability to learn word meaning from text, embeddings, alas, also **reproduce the implicit biases and stereotypes** that were **latent in the text**\n",
    "\n",
    "Besides the notorious $$ \\text{man} : \\text{king} = \\text{woman} : \\text{queen}  $$\n",
    "\n",
    "the same embeddings analogies also **exhibit gender bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\text{man} : \\text{computer programmer} = \\text{woman} : \\text{homemaker}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ \\text{father} : \\text{doctor} = \\text{mother} : \\text{nurse}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bias and Embeddings ‚ö†Ô∏è\n",
    "\n",
    "Bias in the embeddings can cause **allocational harm**\n",
    "\n",
    ">when a system allocates resources (jobs or credit) unfairly to different groups. For example algorithms\n",
    "that use embeddings as part of a search for hiring potential programmers or doctors\n",
    "might thus incorrectly downweight documents with women's names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Bias and Embeddings ‚ö†Ô∏è\n",
    "\n",
    "Bias in the embeddings can cause **representational harm** as in bias towards the ethnicity groups\n",
    "\n",
    "> Using such methods, people\n",
    "in the United States have been shown to associate African-American names with\n",
    "unpleasant words (more than European-American names), male names more with\n",
    "mathematics and female names with the arts, and old people‚Äôs names with unpleasant words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Debiasing in NLP/Machine Learning is an Open-Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Word Embedding: Topics we did NOT cover\n",
    "\n",
    "- **Global Vector - GloVe** Model: taking the best of both word (SVD-based and iterative, word2vec based). Invented by Stanford.\n",
    "- We only skimmed through **[fastext](https://fasttext.cc/)**: extension of word2vec to deal with the **Out of Vocabulary (OOV) problem**\n",
    "    - [Fastext demo with Gensim](https://radimrehurek.com/gensim/auto_examples/tutorials/run_fasttext.html#sphx-glr-auto-examples-tutorials-run-fasttext-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Brief recap of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today's lecture\n",
    "## Supervised, <ins>Parametric</ins> Models\n",
    "#### Propaedeutic part for Deep Learning\n",
    "\n",
    "### 0) Optimization in Deep Learning\n",
    "### 1) Network Structure: Multi-Layer Perceptron (MLP) is a Fully-Connected Neural Net\n",
    "### 2) Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This lecture material is taken from\n",
    "üìò **Chapter 7 Jurafsky Book**\n",
    "\n",
    "Another good yet short resource is [[d2l.ai] Word embedding](https://d2l.ai/chapter_natural-language-processing-pretraining/word2vec.html)\n",
    "\n",
    "- [d2l.ai - Multi Variable Calculus](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/multivariable-calculus.html)\n",
    "- [Karpathy (Tesla Machine Learning Directory) Lecture on Backprop](https://www.youtube.com/watch?v=i94OvYb6noo&t=2985s)\n",
    "- [Stanford Neural Nets and Backprop lecture](https://www.youtube.com/watch?v=mpJ2bFF6o8s)\n",
    "- [Stanford ML notes on Neural Nets](http://cs229.stanford.edu/summer2019/cs229-notes-deep_learning.pdf)\n",
    "- [Stanford ML notes on Backprop](http://cs229.stanford.edu/notes-spring2019/backprop.pdf)\n",
    "- [Animation from jermwatt.github.io  ](https://jermwatt.github.io/machine_learning_refined/notes/3_First_order_methods/3_8_Momentum.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Deep Learning\n",
    "\n",
    "### 0) Quick Intro to Optimization in Deep Learning\n",
    "### 1) What is a Neural Net (just Multi-Layer Perceptron)\n",
    "### 2) How to obtain gradients on the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient Descent or Batch GD\n",
    "\n",
    "- Compute the gradient of the loss wrt to params for **all $n$ training samples**\n",
    "- $\\bmf{\\theta} -\\gamma \\sum_{i=1}^n \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Stochastic Gradient Descent or SGD\n",
    "\n",
    "- Compute the gradient of the loss wrt to params for **a single random training samples**\n",
    "- $\\bmf{\\theta} -\\gamma \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to optimize a Neural Net - SGD over mini-batches\n",
    "\n",
    "\n",
    "1. In-between Batch GD and SGD with a single sample\n",
    "2. We load randomly $k$ samples over the $n$; usually $k$ is a power of 2.\n",
    "    - mini batch of `32, 64, 128` but could also be `100`\n",
    "3. $\\bmf{\\theta} -\\gamma \\sum_{i=1}^k \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$\n",
    "4. Practically you take your training set $\\mathcal{X}$ and you **shuffle** it, then go over it $k$ by $k$. _Simulate uniform random sampling without replacement._\n",
    "    - When the list is over, re-start and shuffle again.\n",
    "5. When you have perfomed a full pass on the shuffled data, this is called an **EPOCH**\n",
    "6. You can train NN over iterations or over **EPOCHS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training scheme Pseudo-code\n",
    "\n",
    "```python\n",
    "from random import shuffle\n",
    "training = list(range(1,11)) # each index points to a training sample, could be a matrix x=HxWx3, label y\n",
    "shuffle(training)\n",
    "converge, it, max_it, k, epoch = False, 0, 100, 3, 0\n",
    "while not converge and it < max_it: # you training convergence scheme\n",
    "    print(f'[Epoch {epoch}]')\n",
    "    for b in range(0, len(training), k): # Data Loader gives you a batch k x matrices\n",
    "        mini_batch = training[b:b+k] # so mini-batch is a tensor HxWx3xk\n",
    "        if len(mini_batch) != k: # a possible way of handling the offset\n",
    "            continue\n",
    "        print('SGD step taken over', mini_batch) # compute the loss/gradients and upate your model\n",
    "        loss.backward()  # get the gradients\n",
    "        optimizer.step() # incorporate in the model\n",
    "        # check convergence and set it to True\n",
    "        it += 1\n",
    "    epoch += 1 # an epoch is done, we reshuffle the training set\n",
    "    shuffle(training)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "> Original unshuffled training set [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "> Training set [10, 8, 1, 2, 6, 4, 9, 7, 5, 3]\n",
    "[Epoch 0]\n",
    "SGD step taken over [10, 8, 1]\n",
    "SGD step taken over [2, 6, 4]\n",
    "SGD step taken over [9, 7, 5]\n",
    "> Training set [1, 10, 6, 9, 3, 7, 8, 4, 5, 2]\n",
    "[Epoch 1]\n",
    "SGD step taken over [1, 10, 6]\n",
    "SGD step taken over [9, 3, 7]\n",
    "SGD step taken over [8, 4, 5]\n",
    "> Training set [6, 3, 10, 5, 9, 8, 4, 7, 2, 1]\n",
    "[Epoch 2]\n",
    "SGD step taken over [6, 3, 10]\n",
    "SGD step taken over [5, 9, 8]\n",
    "SGD step taken over [4, 7, 2]\n",
    "> Training set [1, 2, 5, 10, 6, 7, 9, 8, 3, 4]\n",
    "[Epoch 3]\n",
    "SGD step taken over [1, 2, 5]\n",
    "SGD step taken over [10, 6, 7]\n",
    "SGD step taken over [9, 8, 3]\n",
    "> Training set [2, 3, 1, 9, 6, 8, 4, 10, 7, 5]\n",
    "[Epoch 4]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 1) SGD over mini-batches\n",
    "\n",
    "\n",
    "1. **<ins>Initialization - Very Important if the function is not strictly convex</ins>** \n",
    "$$\\bmf{\\theta} \\sim \\mathcal{N}(\\cdot)~~~\\text{omit details for now}$$ With NN random initialization from a distribution (There are different methods). **We do not set them all to zero**\n",
    "2. Repeat until **convergence**:\n",
    "    - Compute the gradient of the loss wrt to the parameters $\\bmf{\\theta}$ given **the mini-batch**\n",
    "    - Take a small step in the opposite direction of steepest ascent **(so steepest descent).**<br/><br/>\n",
    "     $$\\bmf{\\theta} \\leftarrow  \\bmf{\\theta} -\\sum_{i=1}^k \\gamma \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x},y)$$\n",
    "3. When convergence is reached, you final estimate is in $\\bmf{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Change of vocabulary - A bunch of training samples is a mini-batch\n",
    "\n",
    "- We train NN **Stochastic Gradient Descent** over mini-batches with momentum (or variations thereof)\n",
    "- When you train NN you 'sample' a mini-batch $\\mbf{X}_b$ from your big dataset $\\mbf{X}$.\n",
    "\n",
    "\n",
    "Below this holds for the final linear layer:\n",
    "$$ \\underbrace{\\mbf{Y}}_{\\mathbb{R}^{Kxn}} = \\underbrace{\\mbf{W}}_{\\mathbb{R}^{K\\times d}}\\underbrace{\\mbf{X}_b}_{\\mathbb{R}^{d\\times n}} + \\underbrace{\\mbf{b}}_{\\mathbb{R}^K}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-Batch, Visually\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/batch_SGD_01.png\" width='75%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-Batch SGD vs ~~[Batch]~~ GD\n",
    "\n",
    "Loss in NN in **non-convex** with lots of local-minima so stochasticity adds noise that let the optmization escape from local minima.\n",
    "\n",
    "<div align='center'><img src=\"figs/batch_SGD_02.png\" width='75%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-batch is a sort of smoothing of the single point SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# There is another smoothing technique: Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Top:** SGD: **Bottom:** SGD with momentum increasing memory of previous steps\n",
    "<div align='center'><img src=\"figs/batch_SGD_03.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# SGD over mini-batches with Momentum\n",
    "\n",
    "\n",
    "1. **Initialization - Very Important if the function is not strictly convex** \n",
    "$$\\bmf{\\theta} \\sim \\mathcal{N}~~~\\text{omit details}$$ With NN random initialization from a distribution (There are different methods). **We do not set them all to zero**\n",
    "2. Repeat until **convergence**:\n",
    "    - Compute the gradient of the loss wrt to the parameters $\\bmf{\\theta}$ given **the mini-batch**\n",
    "    - Take a small step in the opposite direction of steepest ascent **(so steepest descent).**<br/><br/>\n",
    "$$\\bmf{\\Delta}_{t+1} = \\alpha\\bmf{\\Delta}_{t} + (1-\\alpha)\\underbrace{\\sum_{i=1}^k\\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)}_{\\text{new update}}$$\n",
    "\n",
    " $$\\bmf{\\theta} \\leftarrow  \\bmf{\\theta} - \\gamma \\bmf{\\Delta}_{t+1}$$\n",
    "3. When convergence is reached (or **EARLY STOPPING**), you final estimate is in $\\bmf{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss Surface for Linear Regression $\\ell_2^2$ loss with $d=2$ parameters in $\\bmf{\\theta}$\n",
    "\n",
    "<div align='center'><img src=\"figs/loss.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# With Deep Learning optimization is highly non-convex and #params explode!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss Surface for ResNet-20 with no skip connection on ImageNet\n",
    "\n",
    "## ResNet-20, number of parameters $\\bmf{\\theta}$ of the order of.....millions!\n",
    "## GPT-3 (LM behind chatpGPT) has 150 billions parameters\n",
    "\n",
    "Visualization of mode connectivity for ResNet-20 with no skip connections on ImageNet dataset. The visualization by Javier Ideami\n",
    "\n",
    "<center><img src=https://izmailovpavel.github.io/curves_blogpost/images/image34.jpg width='50%'/></center>\n",
    "\n",
    "Taken from [https://izmailovpavel.github.io/curves_blogpost/](https://izmailovpavel.github.io/curves_blogpost/)\n",
    "\n",
    "[Video for the curious student](https://www.youtube.com/watch?time_continue=5&v=dqX2LBcp5Hs&feature=emb_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Learning rate is very important\n",
    "<br><br>\n",
    "<center><img src=https://github.com/jermwatt/machine_learning_refined/blob/gh-pages/html/gifs/steplength_1D.gif?raw=true width='85%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Babysitting the training process\n",
    "### Loss in function of epochs\n",
    "\n",
    "<div align='center'><img src=\"figs/loss_types.png\" width='35%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Valleys, Hills, Noisy Surface\n",
    "<br>\n",
    "<center><img src=https://izmailovpavel.github.io/curves_blogpost/images/image1.jpg width='80%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dynamics  of Training\n",
    "\n",
    "<center><img src='http://2.bp.blogspot.com/-q6l20Vs4P_w/VPmIC7sEhnI/AAAAAAAACC4/g3UOUX2r_yA/s400/s25RsOr%2B-%2BImgur.gif' width='30%'><center/>\n",
    "    \n",
    "_**Noisy moons**: This is logistic regression on noisy moons dataset from sklearn which shows the smoothing effects of momentum based techniques (which also results in over shooting and correction). The error surface is visualized as an average over the whole dataset empirically, but the trajectories show the dynamics of minibatches on noisy data. The bottom chart is an accuracy plot._\n",
    "    \n",
    "[taken from here](http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dynamics  of Training\n",
    "\n",
    "<center><img src='http://3.bp.blogspot.com/-nrtJPrdBWuE/VPmIB46F2aI/AAAAAAAACCw/vaE_B0SVy5k/s400/Long%2BValley%2B-%2BImgur.gif' width='30%'><center/>\n",
    "   \n",
    "_**Long valley**: Algos without scaling based on gradient information really struggle to break symmetry here - SGD gets no where and Nesterov Accelerated Gradient / Momentum exhibits oscillations until they build up velocity in the optimization direction. Algos that scale step size based on the gradient quickly break symmetry and begin descent._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Just to give you an hint on where the community is headed with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DALL-E OpenAI (January 2021)\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/dalle.png\" width='85%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DALL-E OpenAI \n",
    "\n",
    "<div align='center'><img src=\"figs/dalle2.png\" width='85%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# OpenAI DALL-E - 12-billion parameters trained with self-supervision\n",
    "\n",
    "Yikes! $12\\times 10^9$ floating points parameters to train\n",
    "\n",
    "> DALL¬∑E is a **12-billion parameter** version of GPT-3 trained to generate images from text descriptions, using a dataset of text‚Äìimage pairs. We‚Äôve found that it has a diverse set of capabilities, including creating anthropomorphized versions of animals and objects, combining unrelated concepts in plausible ways, rendering text, and applying transformations to existing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ~~0) Quick Intro to Optimization in Deep Learning~~\n",
    "### 1) Network Structure: Multi-Layer Perceptron (MLP) is a Fully-Connected Neural Net\n",
    "### 2) Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1) Network Structure: Multi-Layer Perceptron (MLP) \n",
    "# is a Fully-Connected Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Networks and Topics that we do NOT cover\n",
    "\n",
    "You will meet them at **Deep Learning** course\n",
    "\n",
    "- **Convolutional** Neural Nets (good for images or any matrix data like as input)\n",
    "- Generative Adversarial Networks **(GAN)** and adversarial training\n",
    "- AutoEncoders or Variational Autoencoders\n",
    "- Adversarial Attacks to NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Networks and Topics we will cover\n",
    "\n",
    "- Brief Recap on Feedforward NN\n",
    "- Recurrent Neural Nets (RNN such as GRU, LSTM)\n",
    "- Transformer Networks\n",
    "- BERT, GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's go back to single layer, linear soft-max regression or \"linear\" neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's recall last classification layer of a neural net as pipeline\n",
    "## $\\mbf{x} \\implies \\mbf{z}= \\mbf{W}\\mbf{x} + \\mbf{b} \\implies e^{\\mbf{z}}  \\implies \\mbf{p} = \\frac{e^{\\mbf{z}}}{\\sum_k e^{\\mbf{z}}} \\implies -\\ln(\\mbf{p}_y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec with Skip-Gram at a glance\n",
    "\n",
    "... and why it can be seen as a tiny neural net.\n",
    "\n",
    "<div align='center'><img src=\"figs/word2vec_layers.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "Let's consider our linear softmax regressor\n",
    "\n",
    "$$ \\underbrace{\\mbf{z}}_{\\mathbb{R}^{Kx1}} = \\underbrace{\\mbf{W}}_{\\mathbb{R}^{K\\times d}}\\underbrace{\\mbf{x}}_{\\mathbb{R}^{d\\times1}} + \\underbrace{\\mbf{b}}_{\\mathbb{R}^K}$$\n",
    "\n",
    "We interpret as **Linear Layer** $\\mathbf{W} \\mathbf{x}+\\bmf{b}$  followed by  **Non-Linear Activation function** $\\sigma$\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "w_{11} & w_{12} & \\cdots & w_{1 d} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "w_{k 1} & w_{m 2} & \\cdots & w_{k d}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "\\underline{w_{11}} & \\underline{w_{12}} & \\cdots & \\underline{w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "w_{k 1} & w_{m 2} & \\cdots & w_{k d}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "{w_{11}} & {w_{12}} & \\cdots & {w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "\\underline{w_{k 1}} & \\underline{w_{m 2}} & \\cdots & \\underline{w_{k d}}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_2.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer: Linear plus non-Linear\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "{w_{11}} & {w_{12}} & \\cdots & {w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "\\underline{w_{k 1}} & \\underline{w_{m 2}} & \\cdots & \\underline{w_{k d}}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_3.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer: Linear plus non-Linear\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\mathbf{x}=\\left(\\begin{array}{c}\n",
    "-\\text { unit - } \\\\\n",
    "\\vdots \\\\\n",
    "-\\text { unit }-\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "\\mid \\\\\n",
    "\\mathbf{x} \\\\\n",
    "\\mid\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_4.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation as a computational graph\n",
    "<br>\n",
    "\n",
    "<div align='center'><img src=\"figs/graph_00.png\" width='60%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Damn, until now is all linear. So now the \"Deep\"!\n",
    "\n",
    "- Damn, until now is all linear.\n",
    "- Our **beloved SoftMax+CE linear layer** is there **in the end (classifier).**\n",
    "\n",
    "<br>\n",
    "<center><img src=https://www.datasciencecentral.com/wp-content/uploads/2021/10/1-19.png width='70%'/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A single linear layer is not enough for highly  non-linear problems\n",
    "\n",
    "<br><br>\n",
    "<center><img src='https://media-exp1.licdn.com/dms/image/C5112AQEt1wEHRWi21w/article-cover_image-shrink_600_2000/0/1533914799998?e=2147483647&v=beta&t=GsPd5qJePijN7BPx2BEkNiu2OmcixkJGFA5u_XjukVg' width='50%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Adding another non-linear layer before the classifier\n",
    "\n",
    "- We improve the _expressivness_ of our learned function by adding another linear layer **before** the classification layer.\n",
    "- Think this new layer as a feature map $\\mbf{x}  \\mapsto \\phi(\\mbf{x})$; it maps our attribute to a feature space\n",
    "- Now the classifier does not classify anymore directly $\\mbf{x}$ but the feature $\\phi(x)$.\n",
    "- Sorry, notation becomes complex. Upper script means layer index; lower-script selects the unit\n",
    "- $\\mathbf{W}^1 \\in \\mathbb{R}^{d\\times p}$, $\\bmf{b}^1 \\in \\mathbb{R}^{p}$ so then $\\mathbf{W}^2 \\in \\mathbb{R}^{p\\times k}$,   $\\bmf{b}^2 \\in \\mathbb{R}^{k}$\n",
    "\n",
    "$$\\mbf{p}=\\sigma(\\mathbf{W}^2\\underbrace{\\left(\\sigma(\\mathbf{W}^1 \\mathbf{x}  + \\bmf{b}^1) \\right)}_{\\bmf{\\phi}(x)}   + \\bmf{b}^2)$$\n",
    "\n",
    "$$\\text{dim. analysis:} \\quad d \\mapsto p \\mapsto k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# $\\mathbf{W}^1 \\in \\mathbb{R}^{d\\times p}$ is an Hidden Layer\n",
    "\n",
    "Because it maps the original attribute in $d$ from an dimensionality $p$ and then $p$ is used for classifying.\n",
    "\n",
    "A priori you do not know what $\\mathbf{W}^1$ may learn.\n",
    "\n",
    "$$\\mbf{p}=\\sigma(\\mathbf{W}^2\\underbrace{\\left(\\sigma(\\mathbf{W}^1 \\mathbf{x}  + \\bmf{b}^1) \\right)}_{\\bmf{\\phi}(x)}   + \\bmf{b}^2)$$\n",
    "\n",
    "$$\\text{dim. analysis:} \\quad d \\mapsto p \\mapsto k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's update our visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron (MLP) with one hidden layer\n",
    "\n",
    "## Given the nature of these layers, they're called Fully-Connected NN\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_5.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron with one hidden layer\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_6.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Non-linear activation functions:  Sigmoid\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\frac{1}{1+\\exp^{-z}} \\quad \\text{sigmoid or logistic function}$$\n",
    "\n",
    "<br><br> \n",
    "<div align='center'>Smooth and Differentiable alternative to sign<img src=\"figs/sigmoid.png\" width='35%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = 1/(1+np.exp(-x)); dy = np.diff(y); axes[0].plot(x,y); axes[0].legend(['sigmoid']); axes[1].plot(x[1:],dy/step); _=axes[1].legend(['derivative of sigmoid']);": "<img src=\"data:image/png;base64,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\n\"/>"
    }
   },
   "source": [
    "# Non-linear activation functions:  Sigmoid\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\frac{1}{1+\\exp^{-z}} \\quad \\text{sigmoid or logistic function}$$\n",
    "<br><br> <center>Smooth and Differentiable alternative to sign</center>\n",
    "\n",
    "{{import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = 1/(1+np.exp(-x)); dy = np.diff(y); axes[0].plot(x,y); axes[0].legend(['sigmoid']); axes[1].plot(x[1:],dy/step); _=axes[1].legend(['derivative of sigmoid']);}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt; step=0.1;\n",
    "x = np.arange(-20.0, 20.0, step);\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,5));\n",
    "y = 1/(1+np.exp(-x));\n",
    "dy = np.diff(y);\n",
    "axes[0].plot(x,y)\n",
    "axes[0].legend(['sigmoid'])\n",
    "axes[1].plot(x[1:],dy/step);\n",
    "axes[1].legend(['derivative of sigmoid']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = np.maximum(0,x); dy = np.diff(y); axes[0].plot(x,y); axes[1].plot(x[1:],dy/step); axes[0].legend(['ReLu']); _=axes[1].legend(['Deriv of ReLU']);": "<img src=\"data:image/png;base64,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\n\"/>"
    }
   },
   "source": [
    "# Non-linear activation functions:  ReLu - Rectified Linear Unit\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\max(0,z) \\quad \\text{ReLu}$$\n",
    "<br> <center>ReLu is piece-wise linear function</center>\n",
    "{{import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = np.maximum(0,x); dy = np.diff(y); axes[0].plot(x,y); axes[1].plot(x[1:],dy/step); axes[0].legend(['ReLu']); _=axes[1].legend(['Deriv of ReLU']);}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt; step=0.1;\n",
    "x = np.arange(-20.0, 20.0, step);\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,5));\n",
    "y = np.maximum(0,x);\n",
    "dy = np.diff(y);\n",
    "axes[0].plot(x,y)\n",
    "axes[1].plot(x[1:],dy/step);\n",
    "axes[0].legend(['ReLu'])\n",
    "_=axes[1].legend(['Deriv of ReLU']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sigmoid\n",
    "\n",
    "- Used to model output probability\n",
    "- Nowdays not used in middle layers\n",
    "- Have to compute $\\exp()$\n",
    "- **Vanishing gradients** for large input magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# ReLU\n",
    "\n",
    "- Computationally efficient (no exp!)\n",
    "- No vanishing gradients but do not let pass gradients for negative values\n",
    "- Converge much faster than sigmoid (6x)\n",
    "- Not differentiable in zero (subgradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# There are other activation functions we do not cover\n",
    "###  TanH, Leaky ReLU, parametrized ReLU, ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation and Differential Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NN can be huge composition of functions! üò±\n",
    "<br>\n",
    "<center><img src=https://www.researchgate.net/profile/Tiago-Carvalho-8/publication/330478807/figure/fig1/AS:756995804110849@1557493272678/VGG16-VGG19-Inception-V3-Xception-and-ResNet-50-architectures_W640.jpg width='35%'/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Three ways of computing the gradients $\\nabla_{\\mbf{w}}\\mathcal{L}(x,y;\\mbf{w})$\n",
    "\n",
    "1. **Manually** (if we change the network, we have to adjust it for a 100 layer neural net) maybe not a good idea, does not scale, even if we use symbolic derivation tools such as Mathematica ‚úçüèº\n",
    "2. **Finite Difference** good to check the gradients once you have an automatic way of computing it; **very slow, unfeasible in training!** üë©üèæ‚Äçüíª\n",
    "3. **Backpropagation**: application of chain rule of calculus to tensors with a computational graph with caching **(differential programming with automatic differentiation)** üíª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's be clear on what we need to compute\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_6.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Once you have gradients on ALL weights $\\implies$ We can update\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\mbf{W}^l \\leftarrow \\mbf{W}^l - \\gamma \\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\mbf{b}^l \\leftarrow \\mbf{b}^l - \\gamma \\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><img src='figs/neuron_7.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we get all the weight updates?\n",
    "\n",
    "[Mostly taken from here](https://www.youtube.com/watch?v=i94OvYb6noo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule\n",
    "\n",
    "Returning to functions of a single variable,\n",
    "suppose that $y = f(g(x))$\n",
    "and that the underlying functions \n",
    "$y=f(u)$ and $u=g(x)$ \n",
    "are both differentiable.\n",
    "The chain rule states that \n",
    "\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{dy}{du} \\frac{du}{dx}.$$\n",
    "\n",
    "\n",
    "What is the **derivative of loss wrt to x in the equation below**? $$y = loss\\big(g(h(i(x)))\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\frac{\\partial loss}{\\partial x} = \\frac{\\partial loss}{\\partial g} \\frac{\\partial g}{\\partial h}\\frac{\\partial h}{\\partial i}\\frac{\\partial i}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "\n",
    "### Automate the computation of derivatives with computer science\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x} = z\\frac{\\partial q}{\\partial x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x} = z\\cdot 1= z $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "**The computer science way:**\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    " Who is input of $\\mathcal{L}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$q$ and $z$ are input of $\\mathcal{L}$.\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}, \\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}, \\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)?\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)?\n",
    "$$\\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical \"local\" partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_01.png\" width='37%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_02.png\" width='37%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_03.png\" width='37%' ></div>\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_03.png\" width='37%' ></div>\n",
    "\n",
    "**Act as a base case for the recursion:** $$\\frac{\\partial\\mathcal{L}}{\\partial \\mathcal{L}}=?$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_04.png\" width='37%' ></div>\n",
    "\n",
    "**Act as a base case for the recursion:** $$\\frac{\\partial\\mathcal{L}}{\\partial \\mathcal{L}}=1$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_04.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $z$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_05.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $z$?**: \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial z}= q = 3$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_05.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $q$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $q$?**: \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}= z = -4$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $y$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $y$?**: \n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial y} = \\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial y} = z\\cdot 1= -4$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "<div align='center'><img src=\"figs/dag_07.png\" width='37%' ></div>\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Check with our manual derivation ‚úÖ\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_08.png\" width='37%' ></div>\n",
    "\n",
    "The high school way (as we did until now):\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  (\\mbf{x}z+yz)^{\\prime}=(\\mbf{x}z)^{\\prime}+(yz)^{\\prime} = z = -4$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial y} =  (xz+\\mbf{y}z)^{\\prime}=(xz)^{\\prime}+(\\mbf{y}z)^{\\prime} = z = -4$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial z} =  x+y = +3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# You know what? I do not trust math, I want to verify with a machine ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pytorch check\n",
    "```python\n",
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    return (x+y)*z\n",
    "\n",
    "x, y, z = tensor(-2., requires_grad=True), tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z) # forward pass\n",
    "loss.backward()          # backward (after this I can check the gradients)\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)\n",
    "```\n",
    "```\n",
    "tensor(-4.)\n",
    "tensor(-4.)\n",
    "tensor(3.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-4.)\n",
      "tensor(-4.)\n",
      "tensor(3.)\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    loss = (x+y)*z\n",
    "    return loss\n",
    "\n",
    "x, y, z = tensor(-2., requires_grad=True), tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z) # forward pass\n",
    "\n",
    "loss.backward() #backward (ok now I can check the gradients)\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (537812238.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/rt/lg7n4lt1489270pz_18qn1_c0000gp/T/ipykernel_72216/537812238.py\"\u001b[0;36m, line \u001b[0;32m7\u001b[0m\n\u001b[0;31m    x, y, z = tensor(-2.)tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    loss = (x+y)*z\n",
    "    return loss\n",
    "\n",
    "x, y, z = tensor(-2.)tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z)\n",
    "\n",
    "loss.backward()\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Recipe for Chain Rule over DAGs [Forward]\n",
    "\n",
    "**Just remember what you have to do at a generic gate:**\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"figs/local_grad.png\" width='52%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Recipe for Chain Rule over DAGs  [Backward]\n",
    "\n",
    "**Multiply the gradient that you receive with your local gradient**\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"figs/local_grad_01.png\" width='52%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Logistic Regression Computational Graph could be simplified\n",
    "\n",
    "$$\n",
    "f(w, x)=\\frac{1}{1+e^{-\\left(w_{0} x_{0}+w_{1} x_{1}+b\\right)}}\n",
    "$$\n",
    "\n",
    "This is what implement the **Sigmoid Layer in Pytorch:**\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_logistic_reg.png\" width='57%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Are we done with training neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Not completely: till now scalars, but we have matrices and vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now this looks more familiar\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\mbf{W}^l \\leftarrow \\mbf{W}^l - \\gamma \\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\mbf{b}^l \\leftarrow \\mbf{b}^l - \\gamma \\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "<div align='center'><img src=\"figs/graph_01.png\" width='80%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\chain{\\mbf{z}}{\\mbf{W}^1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\underbrace{\\chain{\\mbf{z}}{\\sigma}\\chain{\\mbf{\\sigma}}{\\mbf{W}^1}}_{\\chain{\\mbf{z}}{\\mbf{W}^1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\chain{\\mbf{z}}{\\sigma}\\underbrace{\\chain{\\mbf{\\sigma}}{\\mbf{h}}\\chain{\\mbf{h}}{\\mbf{W}^1}}_{\\chain{\\mbf{\\sigma}}{\\mbf{W}^1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Natural Language Processing with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NLP Task\n",
    "# Sentiment Analysis as a classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "- We focus on one common text **categorization task: sentiment analysis**. \n",
    "- The extraction of sentiment, the positive or negative orientation that a writer expresses toward some object\n",
    "\n",
    "> A review of a movie, book, or product on the web expresses the\n",
    "author‚Äôs sentiment toward the product, while an editorial or political text expresses\n",
    "sentiment toward a candidate or political action. Extracting consumer or public sentiment is thus relevant for fields from marketing to politics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "<div align='center'><img src=\"figs/reviews.png\" width='45%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis: what we want\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/sentiment_analysis.png\" width='80%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sentiment Analysis: what we have\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/sentiment_analysis_training.png\" width='60%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Feedforward Neural Net for Sentiment Analysis \n",
    "## w/ \"hand-designed features\"\n",
    "\n",
    "<br>\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\mathbf{x}=\\left[\\mathbf{x}_1, \\mathbf{x}_2, \\ldots \\mathbf{x}_N\\right] \\quad\\left(\\text { each } \\mathbf{x}_i \\text { is a hand-designed feature }\\right)\\\\\n",
    "& \\mathbf{h}=\\boldsymbol{\\sigma}(\\mathbf{W} \\mathbf{x}+\\mathbf{b}) \\quad\\left(\\text{ hidden layer }\\right) \\\\\n",
    "& \\mathbf{z}=\\mathbf{U h} \\quad\\left(\\text{ classification layer }\\right) \\\\\n",
    "& \\hat{\\mathbf{y}}=\\operatorname{softmax}(\\mathbf{z})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<div align='center'><img src=\"figs/sentiment_analysis_NN_01.png\" width='110%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<div align='center'><img src=\"figs/sentiment_analysis_NN_01.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#  Feedforward Neural Net for Sentiment Analysis \n",
    "## w/ word embeddings\n",
    "\n",
    "We **pool** all the embeddings across the $N$ word tokens we have, using arithmetic mean **(early fusion).**\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "& \\mathbf{x}=\\text{mean}\\left(\\mathbf{e}_1, \\mathbf{e}_2, \\ldots \\mathbf{e}_N\\right) \\quad\\left(\\text { each } \\mathbf{e}_i \\text { is a word2vec embedding}\\right) \\\\\n",
    "& \\mathbf{h}=\\boldsymbol{\\sigma}(\\mathbf{W} \\mathbf{x}+\\mathbf{b}) \\quad\\left(\\text{ hidden layer }\\right) \\\\\n",
    "& \\mathbf{z}=\\mathbf{U h} \\quad\\left(\\text{ classification layer }\\right) \\\\\n",
    "& \\hat{\\mathbf{y}}=\\operatorname{softmax}(\\mathbf{z})\n",
    "\\end{aligned}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<br><br><br>\n",
    "<div align='center'><img src=\"figs/sentiment_analysis_NN_02.png\" width='120%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pretraining\n",
    "\n",
    "Learning a representation on top of another is a very important concept which is related to **pretraining** in Deep Learning. \n",
    "You can think of two alternatives:\n",
    "- **Pretrain** word2vec (**offline**); then tune a 2 layer NN on top of them\n",
    "- **Pretrain** word2vec (**offline**) but also tune the word2vec embeddings as you train the 2 layer NN\n",
    "<div align='center'><img src=\"figs/sentiment_analysis_NN_02.png\" width='50%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NLP Task\n",
    "# Neural Language Model with Feedforward Neural Net\n",
    "\n",
    "<small>Bengio et al, 2003</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Neural Language Model (Pros)\n",
    "\n",
    "\n",
    "Neural language models can handle:\n",
    "- much longer histories, can generalize better over contexts of similar words and;\n",
    "- are more accurate at word-prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Neural Language Model (Cons)\n",
    "\n",
    "On the other hand, neural net language models\n",
    "are:\n",
    "- much more complex, are slower and need more energy to train\n",
    "- are less interpretable than n-gram models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model (LM)\n",
    "\n",
    "**Language Modeling (LM)** is the task of predicting what word comes next:\n",
    "\n",
    "> the students opened their _________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "books, laptops, exams, minds?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model (LM)\n",
    "More formally, given a sequence of words $w_1,\\ldots,w_t$, compute the probabilities distributions over the text words $w_{t+1}$ where the support of the probability is a vocabulary $V$.\n",
    "\n",
    "$$ p(w_{t+1}|w_t,\\ldots,w_1)$$\n",
    "\n",
    "where $w_{t+1}$ can be any word in $V = \\{w_1,\\ldots,_{|V|}\\}$\n",
    "\n",
    "A system that does this is called a **Language Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model (LM)\n",
    "\n",
    "You can also think a LM as a **machinery that assign a probability to a piece of text of T words:**\n",
    "\n",
    "$$ p(w_t,\\ldots,w_1) = \\underbrace{p(w_t,\\ldots,w_2|w_1)}_{\\text{recursion}} \\cdot \\underbrace{p(w_1)}_{\\text{base case}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$ = p(w_t,\\ldots,w_2|w_1) \\cdot p(w_1) = p(w_t,\\ldots,w_3|w_1,w_2)\\cdot p(w_3|w_2,w_1) \\cdot p(w_1) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$= p(w_t,\\ldots,w_3|w_1,w_2)\\cdot p(w_3|w_2,w_1) \\cdot p(w_1) = \\prod_{t=2}^N p(w_{t}|w_{t-1},\\ldots,w_1) \\cdot p(w_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We use LM everyday!\n",
    "\n",
    "<div align='center'><img src=\"figs/swiftk_lm.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# We use LM everyday!\n",
    "\n",
    "<div align='center'><img src=\"figs/google_lm.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model: the order matters!\n",
    "\n",
    "> the cat is small\n",
    "\n",
    "| 0   | 1   | 2  | 3     |\n",
    "|-----|-----|----|-------|\n",
    "| the | cat | is | small |\n",
    "\n",
    "$$p(\\text{the}, \\text{cat}, \\text{is}, \\text{small}) = 0.35$$\n",
    "\n",
    ">small the is cat\n",
    "\n",
    "| 0     | 1   | 2   | 3  |\n",
    "|-------|-----|-----|----|\n",
    "| small | the | cat | is |\n",
    "\n",
    "$$p(\\text{small}, \\text{the}, \\text{cat}, \\text{is}) = 0.0034$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model:  N-gram\n",
    "\n",
    "> the students opened their _________\n",
    "\n",
    "- unigrams: \"the\", \"students\", \"opened\", \"their\"\n",
    "- bigrams: \"the students\", \"students opened\", \"opened their\"\n",
    "- trigrams: \"the students opened\", \"students opened their\"\n",
    "- four-grams: \"the students opened their\"\n",
    "\\begin{equation} \\label{eq1}\n",
    "\\begin{split}\n",
    "p(\\text{the}|\\text{its water is so transparent that})=\\\\\n",
    "\\frac{\\text{count}(\\text{its water is so transparent that the})}{\\text{count}(\\text{its water is so transparent that}}\n",
    "\\end{split}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Language Model:  N-gram problems\n",
    "\n",
    "As you increase the \"window\" of your context:\n",
    "\n",
    "1. ‚ùå  Sparsity issue increases\n",
    "2. ‚ùå  Storage problem increases\n",
    "\n",
    "**Neural LM** took over N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM\n",
    "\n",
    "- Like in N-gram, we consider only a portion of text $N$ window or context size, not the entire text.\n",
    "\n",
    "$$ p(w_{t+1}|w_t,\\ldots,w_1) \\approx p(w_{t+1}|w_t,\\ldots,w_{t-N})$$\n",
    "- Given the context we use a Feedforward NN to predict the next word (similarly to word2vec).\n",
    "\n",
    "> ~~As the proctor started the clock,~~ the students opened their ______________\n",
    "\n",
    "- Unlike N-gram, it uses **distributed representations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM\n",
    "\n",
    "<div align='center'><img src=\"figs/NL_01.png\" width='30%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM\n",
    "\n",
    "<div align='center'><img src=\"figs/NL_math_00.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br><br><div align='center'><img src=\"figs/NL_01.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM\n",
    "\n",
    "‚úÖ Improvements over n-gram LM \n",
    "- No sparsity problem\n",
    "- No need to store all observed n-grams!\n",
    "\n",
    "‚ùå Remaining problems:\n",
    "- Fixed window is too small\n",
    "- Enlarging window enlarges $\\mbf{W}$\n",
    "- Window can never be large enough!\n",
    "- No symmetry in how the inputs are processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<br><br><div align='center'><img src=\"figs/NL_01.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM: \n",
    "\n",
    "<br><div align='center'><img src=\"figs/bengio_2003_00.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM: \n",
    "<br><div align='center'><img src=\"figs/bengio_2003_01.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training the Neural LM: sliding window\n",
    "\n",
    "<br><div align='center'><img src=\"figs/NL_03.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A fixed-window Neural LM: What we need to move forward\n",
    "\n",
    "- An architecture that can process **any arbitrary length of context**\n",
    "- **Handle word order in a better way** than concatenating embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Appendix on Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Gradient Descent or Batch GD\n",
    "\n",
    "- Compute the gradient of the loss wrt to params for **all $n$ training samples**\n",
    "- $\\bmf{\\theta} -\\gamma \\sum_{i=1}^n \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Stochastic Gradient Descent or SGD\n",
    "\n",
    "- Compute the gradient of the loss wrt to params for **a single random training samples**\n",
    "- $\\bmf{\\theta} -\\gamma \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How to optimize a Neural Net - SGD over mini-batches\n",
    "\n",
    "\n",
    "1. In-between Batch GD and SGD with a single sample\n",
    "2. We load randomly $k$ samples over the $n$; usually $k$ is a power of 2.\n",
    "    - mini batch of `32, 64, 128` but could also be `100`\n",
    "3. $\\bmf{\\theta} -\\gamma \\sum_{i=1}^k \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)$\n",
    "4. Practically you take your training set $\\mathcal{X}$ and you **shuffle** it, then go over it $k$ by $k$. _Simulate uniform random sampling without replacement._\n",
    "    - When the list is over, re-start and shuffle again.\n",
    "5. When you have perfomed a full pass on the shuffled data, this is called an **EPOCH**\n",
    "6. You can train NN over iterations or over **EPOCHS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Training scheme Pseudo-code\n",
    "\n",
    "```python\n",
    "from random import shuffle\n",
    "training = list(range(1,11)) # each index points to a training sample, could be a matrix x=HxWx3, label y\n",
    "shuffle(training)\n",
    "converge, it, max_it, k, epoch = False, 0, 100, 3, 0\n",
    "while not converge and it < max_it: # you training convergence scheme\n",
    "    print(f'[Epoch {epoch}]')\n",
    "    for b in range(0, len(training), k): # Data Loader gives you a batch k x matrices\n",
    "        mini_batch = training[b:b+k] # so mini-batch is a tensor HxWx3xk\n",
    "        if len(mini_batch) != k: # a possible way of handling the offset\n",
    "            continue\n",
    "        print('SGD step taken over', mini_batch) # compute the loss/gradients and upate your model\n",
    "        loss.backward()  # get the gradients\n",
    "        optimizer.step() # incorporate in the model\n",
    "        # check convergence and set it to True\n",
    "        it += 1\n",
    "    epoch += 1 # an epoch is done, we reshuffle the training set\n",
    "    shuffle(training)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "> Original unshuffled training set [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "> Training set [10, 8, 1, 2, 6, 4, 9, 7, 5, 3]\n",
    "[Epoch 0]\n",
    "SGD step taken over [10, 8, 1]\n",
    "SGD step taken over [2, 6, 4]\n",
    "SGD step taken over [9, 7, 5]\n",
    "> Training set [1, 10, 6, 9, 3, 7, 8, 4, 5, 2]\n",
    "[Epoch 1]\n",
    "SGD step taken over [1, 10, 6]\n",
    "SGD step taken over [9, 3, 7]\n",
    "SGD step taken over [8, 4, 5]\n",
    "> Training set [6, 3, 10, 5, 9, 8, 4, 7, 2, 1]\n",
    "[Epoch 2]\n",
    "SGD step taken over [6, 3, 10]\n",
    "SGD step taken over [5, 9, 8]\n",
    "SGD step taken over [4, 7, 2]\n",
    "> Training set [1, 2, 5, 10, 6, 7, 9, 8, 3, 4]\n",
    "[Epoch 3]\n",
    "SGD step taken over [1, 2, 5]\n",
    "SGD step taken over [10, 6, 7]\n",
    "SGD step taken over [9, 8, 3]\n",
    "> Training set [2, 3, 1, 9, 6, 8, 4, 10, 7, 5]\n",
    "[Epoch 4]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Images - Mini-batch is a tensor `HxWx3xk`\n",
    "### as an example with RGB images of size $H\\times W$, you have a tensor that contains $k$ images in the mini-batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Video Frames - Mini-batch is a tensor `HxWx3xtxk` \n",
    "### as set of frames from a video, you have a tensor that contains $k$ frames over $t$ time instants of the videos in the mini-batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "training = list(range(1,11))\n",
    "shuffle(training)\n",
    "print('> Training set', training)\n",
    "converge, it, max_it, k, epoch = False, 0, 100, 3, 0\n",
    "while not converge and it < max_it: # you training converge scheme\n",
    "    print(f'[Epoch {epoch}]')\n",
    "    for b in range(0, len(training), k): # Data Loader\n",
    "        mini_batch = training[b:b+k]\n",
    "        if len(mini_batch) != k:\n",
    "            continue\n",
    "        print('SGD step taken over', mini_batch) # compute the loss and upate your model\n",
    "        it += 1\n",
    "    epoch += 1 # epoch is done we reshuffle the training set\n",
    "    shuffle(training)\n",
    "    print('> Training set', training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# 1) SGD over mini-batches\n",
    "\n",
    "\n",
    "1. **<ins>Initialization - Very Important if the function is not strictly convex</ins>** \n",
    "$$\\bmf{\\theta} \\sim \\mathcal{N}(\\cdot)~~~\\text{omit details for now}$$ With NN random initialization from a distribution (There are different methods). **We do not set them all to zero**\n",
    "2. Repeat until **convergence**:\n",
    "    - Compute the gradient of the loss wrt to the parameters $\\bmf{\\theta}$ given **the mini-batch**\n",
    "    - Take a small step in the opposite direction of steepest ascent **(so steepest descent).**<br/><br/>\n",
    "     $$\\bmf{\\theta} \\leftarrow  \\bmf{\\theta} -\\sum_{i=1}^k \\gamma \\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x},y)$$\n",
    "3. When convergence is reached, you final estimate is in $\\bmf{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Change of vocabulary - A bunch of training samples is a mini-batch\n",
    "\n",
    "- We train NN **Stochastic Gradient Descent** over mini-batches with momentum (or variations thereof)\n",
    "- When you train NN you 'sample' a mini-batch $\\mbf{X}_b$ from your big dataset $\\mbf{X}$.\n",
    "\n",
    "\n",
    "Below this holds for the final linear layer:\n",
    "$$ \\underbrace{\\mbf{Y}}_{\\mathbb{R}^{Kxn}} = \\underbrace{\\mbf{W}}_{\\mathbb{R}^{K\\times d}}\\underbrace{\\mbf{X}_b}_{\\mathbb{R}^{d\\times n}} + \\underbrace{\\mbf{b}}_{\\mathbb{R}^K}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-Batch, Visually\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/batch_SGD_01.png\" width='75%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-Batch SGD vs ~~[Batch]~~ GD\n",
    "\n",
    "Loss in NN in **non-convex** with lots of local-minima so stochasticity adds noise that let the optmization escape from local minima.\n",
    "\n",
    "<div align='center'><img src=\"figs/batch_SGD_02.png\" width='75%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Mini-batch is a sort of smoothing of the single point SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# There is another smoothing technique: Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Top:** SGD: **Bottom:** SGD with momentum increasing memory of previous steps\n",
    "<div align='center'><img src=\"figs/batch_SGD_03.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# SGD over mini-batches with Momentum\n",
    "\n",
    "- We introduce an additional term **to remember what happened to the gradient in the\n",
    "previous iteration.** \n",
    "- This memory dampens oscillations and smoothes out the gradient updates.\n",
    "- The memory is implemented with a **exponential moving average**\n",
    "- Usualy $\\alpha$ (the memory param) is set to $0.9$, is a good value.\n",
    "\n",
    "\n",
    "$$\\bmf{\\Delta}_{t} = \\alpha\\bmf{\\Delta}_{t-1} + (1-\\alpha)\\underbrace{\\sum_{i=1}^k\\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)}_{\\text{new update}}$$\n",
    "\n",
    " $$\\bmf{\\theta} \\leftarrow  \\bmf{\\theta} - \\gamma \\bmf{\\Delta}_{t}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# SGD over mini-batches with Momentum\n",
    "\n",
    "\n",
    "1. **Initialization - Very Important if the function is not strictly convex** \n",
    "$$\\bmf{\\theta} \\sim \\mathcal{N}~~~\\text{omit details}$$ With NN random initialization from a distribution (There are different methods). **We do not set them all to zero**\n",
    "2. Repeat until **convergence**:\n",
    "    - Compute the gradient of the loss wrt to the parameters $\\bmf{\\theta}$ given **the mini-batch**\n",
    "    - Take a small step in the opposite direction of steepest ascent **(so steepest descent).**<br/><br/>\n",
    "$$\\bmf{\\Delta}_{t+1} = \\alpha\\bmf{\\Delta}_{t} + (1-\\alpha)\\underbrace{\\sum_{i=1}^k\\bmf{\\nabla}_{\\bmf{\\theta}}\\mathcal{J}(\\mbf{\\theta};\\mbf{x}_i,y_i)}_{\\text{new update}}$$\n",
    "\n",
    " $$\\bmf{\\theta} \\leftarrow  \\bmf{\\theta} - \\gamma \\bmf{\\Delta}_{t+1}$$\n",
    "3. When convergence is reached (or **EARLY STOPPING**), you final estimate is in $\\bmf{\\theta}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss Surface for Linear Regression $\\ell_2^2$ loss with $d=2$ parameters in $\\bmf{\\theta}$\n",
    "\n",
    "<div align='center'><img src=\"figs/loss.png\" width='50%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# With Deep Learning optimization is highly non-convex and #params explode!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Loss Surface for ResNet-20 with no skip connection on ImageNet\n",
    "\n",
    "## ResNet-20, number of parameters $\\bmf{\\theta}$ of the order of.....millions!\n",
    "## GPT-3 (LM behind chatpGPT) has 150 billions parameters\n",
    "\n",
    "Visualization of mode connectivity for ResNet-20 with no skip connections on ImageNet dataset. The visualization by Javier Ideami\n",
    "\n",
    "<center><img src=https://izmailovpavel.github.io/curves_blogpost/images/image34.jpg width='50%'/></center>\n",
    "\n",
    "Taken from [https://izmailovpavel.github.io/curves_blogpost/](https://izmailovpavel.github.io/curves_blogpost/)\n",
    "\n",
    "[Video for the curious student](https://www.youtube.com/watch?time_continue=5&v=dqX2LBcp5Hs&feature=emb_title)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Learning rate is very important\n",
    "<br><br>\n",
    "<center><img src=https://github.com/jermwatt/machine_learning_refined/blob/gh-pages/html/gifs/steplength_1D.gif?raw=true width='85%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Babysitting the training process\n",
    "### Loss in function of epochs\n",
    "\n",
    "<div align='center'><img src=\"figs/loss_types.png\" width='35%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Valleys, Hills, Noisy Surface\n",
    "<br>\n",
    "<center><img src=https://izmailovpavel.github.io/curves_blogpost/images/image1.jpg width='80%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dynamics  of Training\n",
    "\n",
    "<center><img src='http://2.bp.blogspot.com/-q6l20Vs4P_w/VPmIC7sEhnI/AAAAAAAACC4/g3UOUX2r_yA/s400/s25RsOr%2B-%2BImgur.gif' width='30%'><center/>\n",
    "    \n",
    "_**Noisy moons**: This is logistic regression on noisy moons dataset from sklearn which shows the smoothing effects of momentum based techniques (which also results in over shooting and correction). The error surface is visualized as an average over the whole dataset empirically, but the trajectories show the dynamics of minibatches on noisy data. The bottom chart is an accuracy plot._\n",
    "    \n",
    "[taken from here](http://www.denizyuret.com/2015/03/alec-radfords-animations-for.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Dynamics  of Training\n",
    "\n",
    "<center><img src='http://3.bp.blogspot.com/-nrtJPrdBWuE/VPmIB46F2aI/AAAAAAAACCw/vaE_B0SVy5k/s400/Long%2BValley%2B-%2BImgur.gif' width='30%'><center/>\n",
    "   \n",
    "_**Long valley**: Algos without scaling based on gradient information really struggle to break symmetry here - SGD gets no where and Nesterov Accelerated Gradient / Momentum exhibits oscillations until they build up velocity in the optimization direction. Algos that scale step size based on the gradient quickly break symmetry and begin descent._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Just to give you an hint on where the community is headed with Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DALL-E OpenAI (January 2021)\n",
    "<br>\n",
    "<div align='center'><img src=\"figs/dalle.png\" width='85%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# DALL-E OpenAI \n",
    "\n",
    "<div align='center'><img src=\"figs/dalle2.png\" width='85%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# OpenAI DALL-E - 12-billion parameters trained with self-supervision\n",
    "\n",
    "Yikes! $12\\times 10^9$ floating points parameters to train\n",
    "\n",
    "> DALL¬∑E is a **12-billion parameter** version of GPT-3 trained to generate images from text descriptions, using a dataset of text‚Äìimage pairs. We‚Äôve found that it has a diverse set of capabilities, including creating anthropomorphized versions of animals and objects, combining unrelated concepts in plausible ways, rendering text, and applying transformations to existing images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### ~~0) Quick Intro to Optimization in Deep Learning~~\n",
    "### 1) Network Structure: Multi-Layer Perceptron (MLP) is a Fully-Connected Neural Net\n",
    "### 2) Backpropagation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1) Network Structure: Multi-Layer Perceptron (MLP) \n",
    "# is a Fully-Connected Neural Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Networks and Topics that we do NOT cover\n",
    "\n",
    "You will meet them at **Deep Learning** course\n",
    "\n",
    "- **Convolutional** Neural Nets (good for images or any matrix data like as input)\n",
    "- Generative Adversarial Networks **(GAN)** and adversarial training\n",
    "- AutoEncoders or Variational Autoencoders\n",
    "- Adversarial Attacks to NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Networks and Topics we will cover\n",
    "\n",
    "- Brief Recap on Feedforward NN\n",
    "- Recurrent Neural Nets (RNN such as GRU, LSTM)\n",
    "- Transformer Networks\n",
    "- BERT, GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's go back to single layer, linear soft-max regression or \"linear\" neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's recall last classification layer of a neural net as pipeline\n",
    "## $\\mbf{x} \\implies \\mbf{z}= \\mbf{W}\\mbf{x} + \\mbf{b} \\implies e^{\\mbf{z}}  \\implies \\mbf{p} = \\frac{e^{\\mbf{z}}}{\\sum_k e^{\\mbf{z}}} \\implies -\\ln(\\mbf{p}_y) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# word2vec with Skip-Gram at a glance\n",
    "\n",
    "... and why it can be seen as a tiny neural net.\n",
    "\n",
    "<div align='center'><img src=\"figs/word2vec_layers.png\" width='65%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "Let's consider our linear softmax regressor\n",
    "\n",
    "$$ \\underbrace{\\mbf{z}}_{\\mathbb{R}^{Kx1}} = \\underbrace{\\mbf{W}}_{\\mathbb{R}^{K\\times d}}\\underbrace{\\mbf{x}}_{\\mathbb{R}^{d\\times1}} + \\underbrace{\\mbf{b}}_{\\mathbb{R}^K}$$\n",
    "\n",
    "We interpret as **Linear Layer** $\\mathbf{W} \\mathbf{x}+\\bmf{b}$  followed by  **Non-Linear Activation function** $\\sigma$\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "w_{11} & w_{12} & \\cdots & w_{1 d} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "w_{k 1} & w_{m 2} & \\cdots & w_{k d}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "\\underline{w_{11}} & \\underline{w_{12}} & \\cdots & \\underline{w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "w_{k 1} & w_{m 2} & \\cdots & w_{k d}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "{w_{11}} & {w_{12}} & \\cdots & {w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "\\underline{w_{k 1}} & \\underline{w_{m 2}} & \\cdots & \\underline{w_{k d}}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_2.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer: Linear plus non-Linear\n",
    "\n",
    "$$\n",
    "\\sigma(\\mathbf{W} \\mathbf{x}  + \\bmf{b})=\\sigma \\circ\\left(\\begin{array}{cccc}\n",
    "{w_{11}} & {w_{12}} & \\cdots & {w_{1 d}} \\\\\n",
    "w_{21} & w_{22} & \\cdots & w_{2 d} \\\\\n",
    "\\vdots & \\cdots & \\ddots & \\vdots \\\\\n",
    "\\underline{w_{k 1}} & \\underline{w_{m 2}} & \\cdots & \\underline{w_{k d}}\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots \\\\\n",
    "x_{d}\n",
    "\\end{array}\\right)+\n",
    "\\left(\\begin{array}{c}\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "\\vdots \\\\\n",
    "b_{k}\n",
    "\\end{array}\\right)\n",
    "=\\sigma \\circ\\left(\\begin{array}{c}\n",
    "z_{1} \\\\\n",
    "z_{2} \\\\\n",
    "\\vdots \\\\\n",
    "z_{k}\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_3.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation of a Single Layer: Linear plus non-Linear\n",
    "\n",
    "$$\n",
    "\\mathbf{W} \\mathbf{x}=\\left(\\begin{array}{c}\n",
    "-\\text { unit - } \\\\\n",
    "\\vdots \\\\\n",
    "-\\text { unit }-\n",
    "\\end{array}\\right)\\left(\\begin{array}{c}\n",
    "\\mid \\\\\n",
    "\\mathbf{x} \\\\\n",
    "\\mid\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_4.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Representation as a computational graph\n",
    "<br>\n",
    "\n",
    "<div align='center'><img src=\"figs/graph_00.png\" width='60%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Damn, until now is all linear. So now the \"Deep\"!\n",
    "\n",
    "- Damn, until now is all linear.\n",
    "- Our **beloved SoftMax+CE linear layer** is there **in the end (classifier).**\n",
    "\n",
    "<br>\n",
    "<center><img src=https://www.datasciencecentral.com/wp-content/uploads/2021/10/1-19.png width='70%'/></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# A single linear layer is not enough for highly  non-linear problems\n",
    "\n",
    "<br><br>\n",
    "<center><img src='https://media-exp1.licdn.com/dms/image/C5112AQEt1wEHRWi21w/article-cover_image-shrink_600_2000/0/1533914799998?e=2147483647&v=beta&t=GsPd5qJePijN7BPx2BEkNiu2OmcixkJGFA5u_XjukVg' width='50%'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Adding another non-linear layer before the classifier\n",
    "\n",
    "- We improve the _expressivness_ of our learned function by adding another linear layer **before** the classification layer.\n",
    "- Think this new layer as a feature map $\\mbf{x}  \\mapsto \\phi(\\mbf{x})$; it maps our attribute to a feature space\n",
    "- Now the classifier does not classify anymore directly $\\mbf{x}$ but the feature $\\phi(x)$.\n",
    "- Sorry, notation becomes complex. Upper script means layer index; lower-script selects the unit\n",
    "- $\\mathbf{W}^1 \\in \\mathbb{R}^{d\\times p}$, $\\bmf{b}^1 \\in \\mathbb{R}^{p}$ so then $\\mathbf{W}^2 \\in \\mathbb{R}^{p\\times k}$,   $\\bmf{b}^2 \\in \\mathbb{R}^{k}$\n",
    "\n",
    "$$\\mbf{p}=\\sigma(\\mathbf{W}^2\\underbrace{\\left(\\sigma(\\mathbf{W}^1 \\mathbf{x}  + \\bmf{b}^1) \\right)}_{\\bmf{\\phi}(x)}   + \\bmf{b}^2)$$\n",
    "\n",
    "$$\\text{dim. analysis:} \\quad d \\mapsto p \\mapsto k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# $\\mathbf{W}^1 \\in \\mathbb{R}^{d\\times p}$ is an Hidden Layer\n",
    "\n",
    "Because it maps the original attribute in $d$ from an dimensionality $p$ and then $p$ is used for classifying.\n",
    "\n",
    "A priori you do not know what $\\mathbf{W}^1$ may learn.\n",
    "\n",
    "$$\\mbf{p}=\\sigma(\\mathbf{W}^2\\underbrace{\\left(\\sigma(\\mathbf{W}^1 \\mathbf{x}  + \\bmf{b}^1) \\right)}_{\\bmf{\\phi}(x)}   + \\bmf{b}^2)$$\n",
    "\n",
    "$$\\text{dim. analysis:} \\quad d \\mapsto p \\mapsto k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's update our visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron (MLP) with one hidden layer\n",
    "\n",
    "## Given the nature of these layers, they're called Fully-Connected NN\n",
    "\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_5.png' width='70%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Multi-Layer Perceptron with one hidden layer\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_6.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Non-linear activation functions:  Sigmoid\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\frac{1}{1+\\exp^{-z}} \\quad \\text{sigmoid or logistic function}$$\n",
    "\n",
    "<br><br> \n",
    "<div align='center'>Smooth and Differentiable alternative to sign<img src=\"figs/sigmoid.png\" width='35%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = 1/(1+np.exp(-x)); dy = np.diff(y); axes[0].plot(x,y); axes[0].legend(['sigmoid']); axes[1].plot(x[1:],dy/step); _=axes[1].legend(['derivative of sigmoid']);": {}
    }
   },
   "source": [
    "# Non-linear activation functions:  Sigmoid\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\frac{1}{1+\\exp^{-z}} \\quad \\text{sigmoid or logistic function}$$\n",
    "<br><br> <center>Smooth and Differentiable alternative to sign</center>\n",
    "\n",
    "{{import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = 1/(1+np.exp(-x)); dy = np.diff(y); axes[0].plot(x,y); axes[0].legend(['sigmoid']); axes[1].plot(x[1:],dy/step); _=axes[1].legend(['derivative of sigmoid']);}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt; step=0.1;\n",
    "x = np.arange(-20.0, 20.0, step);\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,5));\n",
    "y = 1/(1+np.exp(-x));\n",
    "dy = np.diff(y);\n",
    "axes[0].plot(x,y)\n",
    "axes[0].legend(['sigmoid'])\n",
    "axes[1].plot(x[1:],dy/step);\n",
    "axes[1].legend(['derivative of sigmoid']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "variables": {
     "import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = np.maximum(0,x); dy = np.diff(y); axes[0].plot(x,y); axes[1].plot(x[1:],dy/step); axes[0].legend(['ReLu']); _=axes[1].legend(['Deriv of ReLU']);": {}
    }
   },
   "source": [
    "# Non-linear activation functions:  ReLu - Rectified Linear Unit\n",
    "\n",
    "Very important: **Activation Functions are computed element-wise.**\n",
    "\n",
    "$$ \\sigma(z)= \\max(0,z) \\quad \\text{ReLu}$$\n",
    "<br> <center>ReLu is piece-wise linear function</center>\n",
    "{{import numpy as np; import matplotlib.pyplot as plt; step=0.1; x = np.arange(-20.0, 20.0, step); fig, axes = plt.subplots(1,2,figsize=(12,5)); y = np.maximum(0,x); dy = np.diff(y); axes[0].plot(x,y); axes[1].plot(x[1:],dy/step); axes[0].legend(['ReLu']); _=axes[1].legend(['Deriv of ReLU']);}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np;\n",
    "import matplotlib.pyplot as plt; step=0.1;\n",
    "x = np.arange(-20.0, 20.0, step);\n",
    "fig, axes = plt.subplots(1,2,figsize=(12,5));\n",
    "y = np.maximum(0,x);\n",
    "dy = np.diff(y);\n",
    "axes[0].plot(x,y)\n",
    "axes[1].plot(x[1:],dy/step);\n",
    "axes[0].legend(['ReLu'])\n",
    "_=axes[1].legend(['Deriv of ReLU']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Sigmoid\n",
    "\n",
    "- Used to model output probability\n",
    "- Nowdays not used in middle layers\n",
    "- Have to compute $\\exp()$\n",
    "- **Vanishing gradients** for large input magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "split",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# ReLU\n",
    "\n",
    "- Computationally efficient (no exp!)\n",
    "- No vanishing gradients but do not let pass gradients for negative values\n",
    "- Converge much faster than sigmoid (6x)\n",
    "- Not differentiable in zero (subgradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# There are other activation functions we do not cover\n",
    "###  TanH, Leaky ReLU, parametrized ReLU, ELU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backpropagation and Differential Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# NN can be huge composition of functions! üò±\n",
    "<br>\n",
    "<center><img src=https://www.researchgate.net/profile/Tiago-Carvalho-8/publication/330478807/figure/fig1/AS:756995804110849@1557493272678/VGG16-VGG19-Inception-V3-Xception-and-ResNet-50-architectures_W640.jpg width='35%'/></center>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Three ways of computing the gradients $\\nabla_{\\mbf{w}}\\mathcal{L}(x,y;\\mbf{w})$\n",
    "\n",
    "1. **Manually** (if we change the network, we have to adjust it for a 100 layer neural net) maybe not a good idea, does not scale, even if we use symbolic derivation tools such as Mathematica ‚úçüèº\n",
    "2. **Finite Difference** good to check the gradients once you have an automatic way of computing it; **very slow, unfeasible in training!** üë©üèæ‚Äçüíª\n",
    "3. **Backpropagation**: application of chain rule of calculus to tensors with a computational graph with caching **(differential programming with automatic differentiation)** üíª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Let's be clear on what we need to compute\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "<center><img src='figs/neuron_6.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Once you have gradients on ALL weights $\\implies$ We can update\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\mbf{W}^l \\leftarrow \\mbf{W}^l - \\gamma \\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\mbf{b}^l \\leftarrow \\mbf{b}^l - \\gamma \\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<center><img src='figs/neuron_7.png' width='90%'/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# How do we get all the weight updates?\n",
    "\n",
    "[Mostly taken from here](https://www.youtube.com/watch?v=i94OvYb6noo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule\n",
    "\n",
    "Returning to functions of a single variable,\n",
    "suppose that $y = f(g(x))$\n",
    "and that the underlying functions \n",
    "$y=f(u)$ and $u=g(x)$ \n",
    "are both differentiable.\n",
    "The chain rule states that \n",
    "\n",
    "\n",
    "$$\\frac{dy}{dx} = \\frac{dy}{du} \\frac{du}{dx}.$$\n",
    "\n",
    "\n",
    "What is the **derivative of loss wrt to x in the equation below**? $$y = loss\\big(g(h(i(x)))\\big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\frac{\\partial loss}{\\partial x} = \\frac{\\partial loss}{\\partial g} \\frac{\\partial g}{\\partial h}\\frac{\\partial h}{\\partial i}\\frac{\\partial i}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "\n",
    "### Automate the computation of derivatives with computer science\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "The high school way\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  ?$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "The high school way (as we did until now):\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  (\\mbf{x}z+yz)^{\\prime}=(\\mbf{x}z)^{\\prime}+(yz)^{\\prime} = z$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial y} =  (xz+\\mbf{y}z)^{\\prime}=(xz)^{\\prime}+(\\mbf{y}z)^{\\prime} = z$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial z} =  x+y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x} = z\\frac{\\partial q}{\\partial x} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now with Chain Rule\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "but we can re-write it with the chain rule:\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  \\big(\\underbrace{(\\mbf{x}+y)}_{q}z\\big)^{\\prime}=\\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial x} = z\\cdot 1= z $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "\n",
    "$$\\mathcal{L}(x,y,z) = (x+y)z$$\n",
    "\n",
    "$$x=-2;~y=5;~z=-4;$$\n",
    "\n",
    "**The computer science way:**\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    " Who is input of $\\mathcal{L}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$q$ and $z$ are input of $\\mathcal{L}$.\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}, \\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}, \\frac{\\partial\\mathcal{L}}{\\partial z}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)?\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "What is the derivate? (Just check the operation at the gate)?\n",
    "$$\\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Chain Rule on Directed Acyclic Graph (DAG)\n",
    "Even if the problem is very small, we break it down to subproblem so that we can **automate** it:\n",
    "<div align='center'><img src=\"figs/dag_00.png\" width='35%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical \"local\" partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_01.png\" width='37%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_02.png\" width='37%' ></div>\n",
    "\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "OK now we have all the **analytical partial derivatives, we can compute something**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Forward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_03.png\" width='37%' ></div>\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_03.png\" width='37%' ></div>\n",
    "\n",
    "**Act as a base case for the recursion:** $$\\frac{\\partial\\mathcal{L}}{\\partial \\mathcal{L}}=?$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_04.png\" width='37%' ></div>\n",
    "\n",
    "**Act as a base case for the recursion:** $$\\frac{\\partial\\mathcal{L}}{\\partial \\mathcal{L}}=1$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_04.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $z$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_05.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $z$?**: \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial z}= q = 3$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_05.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $q$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $q$?**: \n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}= z = -4$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $y$?**: \n",
    "\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_06.png\" width='37%' ></div>\n",
    "\n",
    "**What is the value of the gradient of $\\mathcal{L}$ on $y$?**: \n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial y} = \\frac{\\partial\\mathcal{L}}{\\partial q}\\frac{\\partial q}{\\partial y} = z\\cdot 1= -4$$\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Backward Pass\n",
    "<div align='center'><img src=\"figs/dag_07.png\" width='37%' ></div>\n",
    "\n",
    "**This is what we wanted:**\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial x},\\frac{\\partial\\mathcal{L}}{\\partial y},\\frac{\\partial\\mathcal{L}}{\\partial z}$$\n",
    "\n",
    "**This is what we have**\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}}{\\partial q}=z, \\frac{\\partial\\mathcal{L}}{\\partial z}=q, \\frac{\\partial\\mathcal{q}}{\\partial x}=1, \\frac{\\partial\\mathcal{q}}{\\partial y}=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Check with our manual derivation ‚úÖ\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_08.png\" width='37%' ></div>\n",
    "\n",
    "The high school way (as we did until now):\n",
    "\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial x} =  (\\mbf{x}z+yz)^{\\prime}=(\\mbf{x}z)^{\\prime}+(yz)^{\\prime} = z = -4$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial y} =  (xz+\\mbf{y}z)^{\\prime}=(xz)^{\\prime}+(\\mbf{y}z)^{\\prime} = z = -4$$\n",
    "$$\\frac{\\partial\\mathcal{L}(x,y,z)}{\\partial z} =  x+y = +3 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# You know what? I do not trust math, I want to verify with a machine ‚úÖ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pytorch check\n",
    "```python\n",
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    return (x+y)*z\n",
    "\n",
    "x, y, z = tensor(-2., requires_grad=True), tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z) # forward pass\n",
    "loss.backward()          # backward (after this I can check the gradients)\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)\n",
    "```\n",
    "```\n",
    "tensor(-4.)\n",
    "tensor(-4.)\n",
    "tensor(3.)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    loss = (x+y)*z\n",
    "    return loss\n",
    "\n",
    "x, y, z = tensor(-2., requires_grad=True), tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z) # forward pass\n",
    "\n",
    "loss.backward() #backward (ok now I can check the gradients)\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from torch import tensor\n",
    "\n",
    "def neural_net(x,y,z):\n",
    "    loss = (x+y)*z\n",
    "    return loss\n",
    "\n",
    "x, y, z = tensor(-2.)tensor(5.,requires_grad=True), tensor(-4., requires_grad=True)\n",
    "loss = neural_net(x,y,z)\n",
    "\n",
    "loss.backward()\n",
    "for el in [x,y,z]:\n",
    "    print(el.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Recipe for Chain Rule over DAGs [Forward]\n",
    "\n",
    "**Just remember what you have to do at a generic gate:**\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"figs/local_grad.png\" width='52%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# General Recipe for Chain Rule over DAGs  [Backward]\n",
    "\n",
    "**Multiply the gradient that you receive with your local gradient**\n",
    "\n",
    "\n",
    "<div align='center'><img src=\"figs/local_grad_01.png\" width='52%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Logistic Regression Computational Graph could be simplified\n",
    "\n",
    "$$\n",
    "f(w, x)=\\frac{1}{1+e^{-\\left(w_{0} x_{0}+w_{1} x_{1}+b\\right)}}\n",
    "$$\n",
    "\n",
    "This is what implement the **Sigmoid Layer in Pytorch:**\n",
    "\n",
    "<div align='center'><img src=\"figs/dag_logistic_reg.png\" width='57%' ></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Are we done with training neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# Not completely: till now scalars, but we have matrices and vectors!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Now this looks more familiar\n",
    "\n",
    "$\\forall l \\in [1\\ldots,L]$:\n",
    "1. $\\mbf{W}^l \\leftarrow \\mbf{W}^l - \\gamma \\nabla_{\\mbf{W}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "1. $\\mbf{b}^l \\leftarrow \\mbf{b}^l - \\gamma \\nabla_{\\mbf{b}^l}\\mathcal{L}(\\mbf{x},y;\\{\\mbf{W},b\\})$\n",
    "<br><br>\n",
    "<div align='center'><img src=\"figs/graph_01.png\" width='80%' ></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\chain{\\mbf{z}}{\\mbf{W}^1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\underbrace{\\chain{\\mbf{z}}{\\sigma}\\chain{\\mbf{\\sigma}}{\\mbf{W}^1}}_{\\chain{\\mbf{z}}{\\mbf{W}^1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\\chain{\\mathcal{L}}{\\mbf{W}^1} = \\chain{\\loss}{\\mbf{z}}\\chain{\\mbf{z}}{\\sigma}\\underbrace{\\chain{\\mbf{\\sigma}}{\\mbf{h}}\\chain{\\mbf{h}}{\\mbf{W}^1}}_{\\chain{\\mbf{\\sigma}}{\\mbf{W}^1}}$$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "key",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "30",
  "rise": {
   "autolaunch": true,
   "overlay": "<div class='myheader'>Natural Language Processing<img src='../sapienza_logo.png'/></div>",
   "transition": "linear"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Summary",
   "toc_cell": false,
   "toc_position": {
    "height": "47px",
    "left": "1143px",
    "top": "173px",
    "width": "210.344px"
   },
   "toc_section_display": false,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
