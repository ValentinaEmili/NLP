{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.di.uniroma1.it/sites/all/themes/sapienza_bootstrap/logo.png' width=\"200\"/>  \n",
    "\n",
    "# Part_1_11_Vector Semantics (Sparse)\n",
    "\n",
    "In Natural Language Processing (`NLP`), vector semantics provides a powerful framework for representing words and documents in a numerical form, enabling efficient computation and semantic analysis. Sparse vector representations, such as **Bag of Words (`BoW`)**, **TF-IDF**, and **Pointwise Mutual Information (`PPMI`)**, have been foundational in the evolution of `NLP`. These approaches rely on statistical co-occurrence patterns and word frequency to capture linguistic meaning, forming the basis for more sophisticated methods like dense embeddings and contextualized models.\n",
    "\n",
    "Sparse representations are particularly useful in understanding the core principles of vector semantics and building intuition about the role of word-document relationships in tasks like text classification, clustering, and retrieval systems.\n",
    "\n",
    "### **Objectives:**\n",
    "In this notebook, Parham provides an overview of sparse vector semantics, including the key methods used to represent text data and their significance in `NLP`. Through practical exercises, Parham will demonstrate the implementation of **Bag of Words (`BoW`)** for document representation, **TF-IDF** to highlight significant terms within documents, and **PPMI** to extract meaningful statistical relationships from co-occurrence matrices.\n",
    "\n",
    "### **References:**\n",
    "- [https://www.datacamp.com/tutorial/python-bag-of-words-model](https://www.datacamp.com/tutorial/python-bag-of-words-model)  \n",
    "- [https://spotintelligence.com/2022/12/20/bag-of-words-python](https://spotintelligence.com/2022/12/20/bag-of-words-python/)  \n",
    "- [https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus](https://stackoverflow.com/questions/58701337/how-to-construct-ppmi-matrix-from-a-text-corpus)   \n",
    "\n",
    "### **Contributors:**\n",
    "- Parham Membari  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: p.membari96@gmail.com  \n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/p-mem/)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**: [GitHub](https://github.com/parham075)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Medium_logo_Monogram.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Medium**: [Medium](https://medium.com/@p.membari96)  \n",
    "\n",
    "**Table of Contents:**\n",
    "1. Import Libraries  \n",
    "2. Introduction to Vector Semantics  \n",
    "3. Term Frequency-Inverse Document Frequency (`TF-IDF`)   \n",
    "4. Bag of Words (`BoW`) Representation  \n",
    "5. Pointwise Mutual Information (`PMI`)   \n",
    "6. Closing Thoughts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Vector Semantics  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Term Frequency-Inverse Document Frequency (`TF-IDF`)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bag of Words (`BoW`) Representation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pointwise Mutual Information (`PMI`) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Closing Thoughts "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
