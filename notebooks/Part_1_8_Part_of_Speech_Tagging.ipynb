{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://www.di.uniroma1.it/sites/all/themes/sapienza_bootstrap/logo.png' width=\"200\"/>  \n",
    "\n",
    "# Part_1_8_Part_of_Speech_Tagging  \n",
    "\n",
    "In Natural Language Processing (`NLP`), tagging is a crucial process for annotating text with meaningful labels that aid in linguistic and semantic analysis. Among these, **Part-of-Speech (`POS`) tagging** plays a foundational role in identifying the grammatical roles of words in a sentence, such as noun, verb, adjective, or adverb. This understanding is critical for tasks like syntactic parsing, named entity recognition, machine translation, and text-to-speech systems.  \n",
    "\n",
    "`POS` tagging methods have evolved from rule-based systems to sophisticated algorithms like **Hidden Markov Models (`HMMs`)** and **Conditional Random Fields (CRFs)**, which leverage statistical properties for better contextual analysis. More recently, **neural network-based models** have introduced significant advancements, enabling state-of-the-art performance by leveraging word embeddings and deep learning architectures.  \n",
    "\n",
    "### **Objectives:**  \n",
    "In this notebook, Parham provides an overview of Part-of-Speech tagging, its significance in `NLP`, and the algorithms behind it, including Hidden Markov Models (`HMMs`) and neural networks. Through practical exercises, Parham will train a neural network for `POS` tagging and use `NLTK` to implement the Stanford `POS` Tagger.  \n",
    "\n",
    "### **References:**  \n",
    "- [https://www.nltk.org/book/ch05.html](https://www.nltk.org/book/ch05.html)  \n",
    "- [https://web.stanford.edu/~jurafsky/slp3/old_oct19/8.pdf](https://web.stanford.edu/~jurafsky/slp3/old_oct19/8.pdf)  \n",
    "- [https://www.linguisticsweb.org/doku.php?id=linguisticsweb:tutorials:linguistics_tutorials:automaticannotation:stanford_pos_tagger_python](https://www.linguisticsweb.org/doku.php?id=linguisticsweb:tutorials:linguistics_tutorials:automaticannotation:stanford_pos_tagger_python)  \n",
    "- [https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "\n",
    "### **Contributors:**  \n",
    "- Parham Membari  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Gmail_icon_%282020%29.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Email**: p.membari96@gmail.com  \n",
    "    - <img src=\"https://www.iconsdb.com/icons/preview/red/linkedin-6-xxl.png\" alt=\"Logo\" width=\"20\" height=\"20\"> **LinkedIn**: [LinkedIn](https://www.linkedin.com/in/p-mem/)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/a/ae/Github-desktop-logo-symbol.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **GitHub**: [GitHub](https://github.com/parham075)  \n",
    "    - <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ec/Medium_logo_Monogram.svg\" alt=\"Logo\" width=\"20\" height=\"20\"> **Medium**: [Medium](https://medium.com/@p.membari96)  \n",
    "\n",
    "**Table of Contents:**  \n",
    "1. Import Libraries\n",
    "2. Introduction to Tagging in NLP  \n",
    "3. Algorithms Behind `POS` Tagging (Rule-Based, HMM, Neural Networks)  \n",
    "4. Fine tunning of a Neural Network for `POS` Tagging  \n",
    "5. Using NLTK to Handle Stanford POS Tagger  \n",
    "6. Closing Thoughts  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Introduction to Tagging in NLP  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n Natural Language Processing (NLP), **tagging** involves assigning meaningful labels to elements of text, such as words, phrases, or sentences. These labels capture linguistic or semantic information that is essential for various NLP applications. For example:  \n",
    "- **Part-of-Speech (POS) Tagging:** Assigns grammatical roles (e.g., noun, verb, adjective).  \n",
    "\n",
    "- **Named Entity Recognition (NER):** Identifies proper nouns like names, locations, or organizations.  \n",
    "\n",
    "- **Semantic Role Labeling (SRL):** Describes the roles words play in the semantic structure of a sentence.  \n",
    "\n",
    "Each tagging approach serves a unique purpose, contributing to tasks like text parsing, translation, summarization, and information extraction. Techniques for tagging range from traditional rule-based systems to modern neural network-based methods:  \n",
    "- **Rule-Based Tagging:** Relies on linguistic rules and patterns. It works well for predictable structures but struggles with ambiguity and language variability.  \n",
    "- **Statistical Tagging:** Algorithms like Hidden Markov Models (HMMs) and Conditional Random Fields (CRFs) use probabilistic methods to predict tags based on contextual patterns in labeled data.  \n",
    "- **Neural Network-Based Tagging:** Leverages word embeddings and deep learning architectures like BiLSTMs and Transformers to achieve state-of-the-art performance by capturing complex patterns in language.  \n",
    "\n",
    "### 2.1. Part-of-Speech Tagging: A Closer Look  \n",
    "\n",
    "Among these approaches, **Part-of-Speech (POS) tagging** is a foundational task in NLP. It identifies the grammatical role of each word in a sentence, helping to structure raw text for downstream tasks. Consider the sentence:  \n",
    "\n",
    "_\"Computer Science department of Sapienza University of Rome is intellectually lively and reputed for its research outcome.\"_  \n",
    "\n",
    "POS tagging identifies:  \n",
    "- Computer      → Proper Noun (NNP)  \n",
    "- Science       → Proper Noun (NNP)  \n",
    "- department    → Noun (NN)  \n",
    "- of            → Preposition (IN)  \n",
    "- Sapienza      → Proper Noun (NNP)  \n",
    "- University    → Proper Noun (NNP)  \n",
    "- of            → Preposition (IN)  \n",
    "- Rome          → Proper Noun (NNP)  \n",
    "- is            → Verb (VBZ)  \n",
    "- intellectually → Adverb (RB)  \n",
    "- lively        → Adjective (JJ)  \n",
    "- and           → Coordinating Conjunction (CC)  \n",
    "- reputed       → Verb, Past Participle (VBN)  \n",
    "- for           → Preposition (IN)  \n",
    "- its           → Possessive Pronoun (PRP$)  \n",
    "- research      → Noun (NN)  \n",
    "- outcome       → Noun (NN)  \n",
    "\n",
    "> Note: for more identifiers please check this [documentation](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html)\n",
    "\n",
    "By providing information about grammatical structure, this tagging helps machines understand not just individual words, but also the connections between them within a sentence.\n",
    "\n",
    "### 2.2. Two classes of words: **Open** vs. **Closed**:\n",
    "- Closed class words\n",
    "    - Relatively fixed membership\n",
    "    - Usually function words: short, frequent words with grammatical function\n",
    "    - determiners: a, an, the\n",
    "    - pronouns: she, he, I\n",
    "    - prepositions: on, under, over, near, by, …\n",
    "- Open class words\n",
    "    - Usually content words: Nouns, Verbs, Adjectives, Adverbs\n",
    "    - Plus interjections: oh, ouch, uh-huh, yes, hello\n",
    "    - New nouns and verbs like iPhone or to fax\n",
    "\n",
    "\n",
    "\n",
    "### 2.3. Why Part-of-Speech Tagging?  \n",
    "\n",
    "Here’s why POS tagging is so valuable:  \n",
    "\n",
    "- **Supports Other NLP Tasks**: POS tagging provides crucial insights for tasks like syntactic parsing, sentiment analysis, and text-to-speech systems.  \n",
    "- **Parsing**: Knowing POS tags can improve syntactic parsing accuracy, which is vital for machine translation and language understanding.  \n",
    "- **Machine Translation (MT)**: POS tags help reordering structures, such as adjectives and nouns, when translating between languages like Spanish and English.  \n",
    "- **Sentiment Analysis**: Distinguishing adjectives or verbs can reveal sentiment or emotional tone in text.  \n",
    "- **Text-to-Speech**: Pronunciation ambiguity, as seen with words like *lead* or *object*, can be resolved using POS tags.  \n",
    "- **Linguistic Analysis**: POS tagging aids in studying linguistic evolution, identifying meaning shifts, and creating new words.  \n",
    "\n",
    "In short, POS tagging acts as a bridge, enabling both practical NLP tasks and linguistic research to benefit from accurate syntactic understanding.  \n",
    "\n",
    "\n",
    "### 2.4. How Difficult is POS Tagging in English?  \n",
    "\n",
    "Although English `POS` tagging has achieved high accuracy, it is not without challenges. Ambiguity is a major issue:  \n",
    "\n",
    "- About **15% of word types** in English are ambiguous (e.g., *back* can be a noun, verb, adjective, or adverb).  \n",
    "- However, **85% of word types are unambiguous** (e.g., *Sapienza* is always a proper noun, and *intellectually* is always an adverb).  \n",
    "- The ambiguous 15% are highly frequent in text, meaning **~60% of word tokens** in actual usage are ambiguous.  \n",
    "\n",
    "Here are examples of how the word *back* varies based on context:  \n",
    "\n",
    "- **Adjective (ADJ)**: _Earnings growth took a **back** seat._  \n",
    "- **Noun (NOUN)**: _A small building in the **back**._  \n",
    "- **Verb (VERB)**: _A clear majority of senators **back** the bill._  \n",
    "- **Particle (PART)**: _Enable the country to buy **back** debt._  \n",
    "- **Adverb (ADV)**: _I was twenty-one **back** then._  \n",
    "\n",
    "\n",
    "### 2.5. POS Tagging Performance  \n",
    "\n",
    "How accurate is POS tagging? Modern methods have achieved impressive results:  \n",
    "\n",
    "- **Tagging Accuracy**: About **97%**, which hasn't changed much in the last decade. Hidden Markov Models (HMMs), Conditional Random Fields (CRFs), and neural network-based approaches like BERT perform similarly.  \n",
    "- **Baseline Accuracy**: Even a \"stupid\" baseline, such as tagging every word with its most frequent tag or unknown words as nouns, achieves **92%** accuracy.  \n",
    "\n",
    "The high accuracy is partly because many words are unambiguous. However, improving the remaining 3% can be difficult due to rare and ambiguous cases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Algorithms Behind `POS` Tagging (Rule-Based, HMM, Neural Networks) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Fine tunning of a Neural Network for `POS` Tagging  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Using NLTK to Handle Stanford POS Tagger  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Closing Thoughts  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
