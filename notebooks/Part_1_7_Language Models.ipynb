{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Part_1_7_Language Models**\n",
    "\n",
    "In the evolving field of Natural Language Processing (NLP), **Language Models** are foundational in generating, understanding, and analyzing text. From classic statistical models like `n-grams` to advanced Large Language Models (`LLMs`) like those powering modern conversational AI, language models shape applications across search engines, chatbots, summarization, translation, and more. This tutorial covers two main aspects of language models: **n-grams** and **Large Language Models (LLMs)**, along with hands-on exercises using the the **ChatGPT API** and **LangChain** to build sophisticated prompt engineering workflows.\n",
    "\n",
    "### **Objectives:**\n",
    "\n",
    "By the end of this notebook, Parham will:\n",
    "1. Gain an understanding of **n-gram language models**, their structure, and their role in basic text generation and probability-based language modeling.\n",
    "2. Develop a fundamental knowledge of **Large Language Models (LLMs)** and their powerful role in NLP, including how they interpret and generate text in a human-like manner.\n",
    "3. Learn to interact with an LLM, specifically through the **ChatGPT API** and **LangChain**.\n",
    "4. Experiment with **prompt engineering** techniques to customize language model outputs, creating contextually relevant and refined responses.\n",
    "\n",
    "### **Table of Contents:**\n",
    "1. Import Libraries\n",
    "2. Introduction to Language Modeling\n",
    "3. N-gram Models\n",
    "   <!-- - Overview and Theory\n",
    "   - Implementing Unigram, Bigram, and Trigram Models\n",
    "   - Probability and Smoothing Techniques\n",
    "   - Applications and Limitations of N-gram Models -->\n",
    "4. Using ChatGPT API for Language Modeling\n",
    "   <!-- - Introduction to OpenAIâ€™s ChatGPT API\n",
    "   - Basic Setup and Request Handling\n",
    "   - Generating Text and Answering Questions -->\n",
    "5. LangChain and Prompt Engineering\n",
    "   <!-- - Overview of LangChain for Building Applications with LLMs\n",
    "   - Basics of Prompt Engineering: Designing Effective Prompts\n",
    "   - Experimenting with Prompt Variations to Improve Model Responses\n",
    "   - Use Cases: Building a Question-Answering Bot, Text Summarizer, or Conversational Agent -->\n",
    "6. Closing Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy\n",
    "import spacy\n",
    "from loguru import logger\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "from nltk.corpus import words\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Introduction to Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modeling is the way of determining the probability of any sequence of words. Language modeling is used in various applications such as Speech Recognition, Spam filtering, etc. Language modeling is the key aim behind implementing many state-of-the-art Natural Language Processing models.\n",
    "\n",
    "### Methods of Language Modelling\n",
    "Two methods of Language Modeling:\n",
    "\n",
    "- **Statistical Language Modelling**: Statistical Language Modeling, or Language Modeling, is the development of probabilistic models that can predict the next word in the sequence given the words that precede. Examples such as N-gram language modeling.\n",
    "\n",
    "- **Neural Language Modeling**: Neural network methods are achieving better results than classical methods both on standalone language models and when models are incorporated into larger models on challenging tasks like speech recognition and machine translation. A way of performing a neural language model is through word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-gram Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview and Theory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using ChatGPT API for Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LangChain and Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Closing Thoughts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
